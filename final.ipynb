{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9189e36-34da-420b-bb4c-77fb5a50c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a36f4-3bae-40f1-9fbd-4ae3c230f70b",
   "metadata": {},
   "source": [
    "# MERGE ALL THE DATA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc411bd-3060-41c0-9fe8-ff97404d53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datasets\n",
    "filepaths_left={\n",
    "    \"pvs1_gps_mpu\" : r\"archive/PVS 1/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs2_gps_mpu\" : r\"archive/PVS 2/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs3_gps_mpu\" : r\"archive/PVS 3/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs4_gps_mpu\" : r\"archive/PVS 4/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs5_gps_mpu\" : r\"archive/PVS 5/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs6_gps_mpu\" : r\"archive/PVS 6/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs7_gps_mpu\" : r\"archive/PVS 7/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs8_gps_mpu\" : r\"archive/PVS 8/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs9_gps_mpu\" : r\"archive/PVS 9/dataset_gps_mpu_left.csv\"\n",
    "}\n",
    "\n",
    "filepaths_right={\n",
    "    \"pvs1_gps_mpu\" : r\"archive/PVS 1/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs2_gps_mpu\" : r\"archive/PVS 2/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs3_gps_mpu\" : r\"archive/PVS 3/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs4_gps_mpu\" : r\"archive/PVS 4/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs5_gps_mpu\" : r\"archive/PVS 5/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs6_gps_mpu\" : r\"archive/PVS 6/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs7_gps_mpu\" : r\"archive/PVS 7/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs8_gps_mpu\" : r\"archive/PVS 8/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs9_gps_mpu\" : r\"archive/PVS 9/dataset_gps_mpu_right.csv\"\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Left and right corresponds to sensordata from either side of the cars\n",
    "datasets_left = {name:pd.read_csv(path) for name,path in filepaths_left.items()}\n",
    "datasets_right = {name:pd.read_csv(path) for name,path in filepaths_right.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec31e05-9e2a-4510-bc2f-00d1330f3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(left, right, name ):\n",
    "    pvs= pd.concat([left, right], axis=1)\n",
    "    length= len(left)\n",
    "\n",
    "    # Renaming labels\n",
    "    pvs.columns = [\n",
    "    'timestamp', 'acc_x_dashboard_l', 'acc_y_dashboard_l', 'acc_z_dashboard_l',\n",
    "    'acc_x_above_suspension_l', 'acc_y_above_suspension_l', 'acc_z_above_suspension_l', \n",
    "    'acc_x_below_suspension_l', 'acc_y_below_suspension_l', 'acc_z_below_suspension_l', \n",
    "    'gyro_x_dashboard_l', 'gyro_y_dashboard_l', 'gyro_z_dashboard_l', 'gyro_x_above_suspension_l', \n",
    "    'gyro_y_above_suspension_l', 'gyro_z_above_suspension_l', 'gyro_x_below_suspension_l', \n",
    "    'gyro_y_below_suspension_l', 'gyro_z_below_suspension_l', 'mag_x_dashboard_l', 'mag_y_dashboard_l', \n",
    "    'mag_z_dashboard_l', 'mag_x_above_suspension_l', 'mag_y_above_suspension_l', 'mag_z_above_suspension_l', \n",
    "    'temp_dashboard_l', 'temp_above_suspension_l', 'temp_below_suspension_l', 'timestamp_gps', \n",
    "    'latitude', 'longitude', 'speed', 'timestamp', 'acc_x_dashboard_r', 'acc_y_dashboard_r', \n",
    "    'acc_z_dashboard_r', 'acc_x_above_suspension_r', 'acc_y_above_suspension_r', \n",
    "    'acc_z_above_suspension_r', 'acc_x_below_suspension_r', 'acc_y_below_suspension_r', \n",
    "    'acc_z_below_suspension_r', 'gyro_x_dashboard_r', 'gyro_y_dashboard_r', 'gyro_z_dashboard_r', \n",
    "    'gyro_x_above_suspension_r', 'gyro_y_above_suspension_r', 'gyro_z_above_suspension_r', \n",
    "    'gyro_x_below_suspension_r', 'gyro_y_below_suspension_r', 'gyro_z_below_suspension_r', \n",
    "    'mag_x_dashboard_r', 'mag_y_dashboard_r', 'mag_z_dashboard_r', 'mag_x_above_suspension_r', \n",
    "    'mag_y_above_suspension_r', 'mag_z_above_suspension_r', 'temp_dashboard_r', 'temp_above_suspension_r', \n",
    "    'temp_below_suspension_r', 'timestamp_gps', 'latitude', 'longitude', 'speed'\n",
    "    ]\n",
    "    \n",
    "\n",
    "    # Remove duplicate columns (those with the same name, e.g., 'timestamp_gps', 'latitude', etc.)\n",
    "    pvs_removed = pvs.loc[:, ~pvs.columns.duplicated()]\n",
    "\n",
    "    # Columns to keep. We try these first\n",
    "    to_keep=[\"timestamp\",\n",
    "             \"acc_x_dashboard_l\",\n",
    "             \"acc_y_dashboard_l\",\n",
    "             \"acc_z_dashboard_l\",\n",
    "             \"speed\",\n",
    "             \"gyro_x_dashboard_l\",\n",
    "             \"gyro_y_dashboard_l\",\n",
    "             \"gyro_z_dashboard_l\"\n",
    "            ]\n",
    "    \n",
    "    pvs_removed=pvs_removed[to_keep]\n",
    "\n",
    "    #create the driver column ( target )\n",
    "    if name in (\"pvs1_gps_mpu\",\"pvs4_gps_mpu\",\"pvs7_gps_mpu\"):\n",
    "        pvs_removed['Driver'] = 1\n",
    "    elif name in (\"pvs2_gps_mpu\",\"pvs5_gps_mpu\",\"pvs8_gps_mpu\"):\n",
    "        pvs_removed['Driver'] = 2\n",
    "    else: \n",
    "        pvs_removed['Driver'] = 3\n",
    "        \n",
    "    return pvs_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160e4e4-0eda-4735-95a5-6030e383aa79",
   "metadata": {},
   "source": [
    "### CREATE TARGETS\n",
    "We want to predict the driver, and we know that each PVS contains data regarding one single driver. \n",
    "As a conseguence, we can simply create a dataframe containing the same values repeated n times for each PVS.\n",
    "\n",
    "The datasets refer to the following drivers: \n",
    "\n",
    "PVS1--> 1\n",
    "\n",
    "PVS2--> 2\n",
    "\n",
    "PVS3--> 3\n",
    "\n",
    "PVS4--> 1\n",
    "\n",
    "PVS5--> 2\n",
    "\n",
    "PVS6--> 3\n",
    "\n",
    "PVS7--> 1\n",
    "\n",
    "PVS8--> 2\n",
    "\n",
    "PVS9--> 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1019e49-d0aa-4f92-9b05-c7600c1a4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the merge function to create the new versions of the datasets\n",
    "datasets = {name: merge(datasets_left[name],datasets_right[name], name) for name in datasets_right.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fde2705e-dfd0-4d6e-b86c-1f0a9b70bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver\n",
      "gyro_z_dashboard_l\n",
      "gyro_x_dashboard_l\n",
      "acc_z_dashboard_l\n",
      "acc_x_dashboard_l\n",
      "gyro_y_dashboard_l\n",
      "speed\n",
      "timestamp\n",
      "acc_y_dashboard_l\n"
     ]
    }
   ],
   "source": [
    "#print all the features \n",
    "columns=set()\n",
    "for name,dataset in datasets.items():\n",
    "    columns.update(list(dataset.columns))\n",
    "\n",
    "for el in columns:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6e430d-e581-4f3b-9a1d-464df1ed8d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>acc_x_dashboard_l</th>\n",
       "      <th>acc_y_dashboard_l</th>\n",
       "      <th>acc_z_dashboard_l</th>\n",
       "      <th>speed</th>\n",
       "      <th>gyro_x_dashboard_l</th>\n",
       "      <th>gyro_y_dashboard_l</th>\n",
       "      <th>gyro_z_dashboard_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.577219e+09</td>\n",
       "      <td>0.365116</td>\n",
       "      <td>0.167893</td>\n",
       "      <td>9.793961</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>-0.133896</td>\n",
       "      <td>-0.018883</td>\n",
       "      <td>0.138092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.577219e+09</td>\n",
       "      <td>0.392649</td>\n",
       "      <td>0.176273</td>\n",
       "      <td>9.771216</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>-0.003624</td>\n",
       "      <td>0.000763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.577219e+09</td>\n",
       "      <td>0.409408</td>\n",
       "      <td>0.181062</td>\n",
       "      <td>9.732909</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>0.125504</td>\n",
       "      <td>-0.186729</td>\n",
       "      <td>-0.090790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.577219e+09</td>\n",
       "      <td>0.371101</td>\n",
       "      <td>0.164302</td>\n",
       "      <td>9.749668</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>-0.088120</td>\n",
       "      <td>-0.034142</td>\n",
       "      <td>0.046539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.577219e+09</td>\n",
       "      <td>0.390255</td>\n",
       "      <td>0.159514</td>\n",
       "      <td>9.869378</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>-0.179672</td>\n",
       "      <td>0.118446</td>\n",
       "      <td>-0.182343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  acc_x_dashboard_l  acc_y_dashboard_l  acc_z_dashboard_l  \\\n",
       "0  1.577219e+09           0.365116           0.167893           9.793961   \n",
       "1  1.577219e+09           0.392649           0.176273           9.771216   \n",
       "2  1.577219e+09           0.409408           0.181062           9.732909   \n",
       "3  1.577219e+09           0.371101           0.164302           9.749668   \n",
       "4  1.577219e+09           0.390255           0.159514           9.869378   \n",
       "\n",
       "      speed  gyro_x_dashboard_l  gyro_y_dashboard_l  gyro_z_dashboard_l  \n",
       "0  0.009128           -0.133896           -0.018883            0.138092  \n",
       "1  0.009128           -0.027084           -0.003624            0.000763  \n",
       "2  0.009128            0.125504           -0.186729           -0.090790  \n",
       "3  0.009128           -0.088120           -0.034142            0.046539  \n",
       "4  0.009128           -0.179672            0.118446           -0.182343  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"pvs1_gps_mpu\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf49bd62-576e-4fb8-b0c7-7e5478ab107b",
   "metadata": {},
   "source": [
    "# WORK ON CORRELATION (OPTIONAL SO FAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59ff09-30ed-4df9-b9d3-de675accbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation(df,plot=False):\n",
    "\n",
    "    # Only compute using the numeric data types in the dataset\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    \n",
    "    #print(numeric_df.columns)\n",
    "    correlation_matrix=numeric_df.corr()\n",
    "\n",
    "    if not plot:\n",
    "        return correlation_matrix\n",
    "        \n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(18, 14))  # Increase the size of the figure\n",
    "    \n",
    "    # Plot the heatmap with adjusted figure size\n",
    "    sns.heatmap(correlation_matrix, annot=False, fmt='.2f', cmap='coolwarm', linewidths=0.5,vmin=-1, vmax=1)\n",
    "    \n",
    "    # Rotate the tick labels for better readability and shrink font size\n",
    "    plt.xticks(rotation=90, fontsize=8)  # Rotate x-axis labels by 90 degrees and adjust font size\n",
    "    plt.yticks(rotation=0, fontsize=8)   # Keep y-axis labels horizontal and adjust font size\n",
    "    \n",
    "    # Add a title with smaller font size\n",
    "    plt.title(\"Correlation Matrix\", fontsize=12)\n",
    "    \n",
    "    # Show the plot with a tight layout\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "    plt.show()\n",
    "\n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b67c6eba-8a30-4cc2-b7e2-a0bc1faf9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_correlation={name: compute_correlation(datasets[name]) for name in datasets.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd515f4-b177-4da6-929e-862a62661237",
   "metadata": {},
   "source": [
    "## REDUCE THE DATA\n",
    "Try to reduce the data by merging k consecutive lines ( reduce by a factor of k )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c7f8bc-0c70-40c5-8606-057b48b57785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n"
     ]
    }
   ],
   "source": [
    "#reduce the number of rows of the dataset\n",
    "def reduce_df(df,ratio):\n",
    "    new = pd.DataFrame()\n",
    "    for i in range(0, len(df) - 1, ratio):  # Step by 2 to get pairs\n",
    "\n",
    "        if i%10000==0:\n",
    "            print(i)\n",
    "            \n",
    "        row1 = df.iloc[i]\n",
    "        row2 = df.iloc[i + 1]\n",
    "        # Calculate the mean of the pair (assuming numeric data)\n",
    "        merged_row = (row1 + row2) / 2\n",
    "        \n",
    "        # Append the result as a new row to `new`\n",
    "        new = pd.concat([new, merged_row.to_frame().T], ignore_index=True)\n",
    "        \n",
    "    return new\n",
    "\n",
    "ratio=4\n",
    "datasets_reduced={name:reduce_df(datasets[name],ratio) for name in datasets.keys()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732982ca-7357-4f13-8548-8d5417af67e3",
   "metadata": {},
   "source": [
    "## WORK ON A WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d5855eb-60d6-4bbf-ba11-a1f8b8be7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_timestamp(df):\n",
    "    to_remove=[\"timestamp_max\",\"timestamp_min\",\"timestamp_mean\",\"timestamp_STD\"]\n",
    "    new= df.drop(columns=to_remove, axis=1, errors='ignore')\n",
    "\n",
    "    return new\n",
    "\n",
    "def update_name(df):\n",
    "    #print(df.columns)\n",
    "    #df = df.loc[:, ~df.columns.str.contains('timestamp')]  # Remove columns containing 'timestamp'\n",
    "    new_column_names = [ 'timestamp_max','acc_x_dashboard_l_max', 'acc_y_dashboard_l_max', \n",
    "        'acc_z_dashboard_l_max', 'speed_max', 'gyro_x_dashboard_l_max', \n",
    "        'gyro_y_dashboard_l_max', 'gyro_z_dashboard_l_max', \n",
    "        'timestamp_min', 'acc_x_dashboard_l_min', 'acc_y_dashboard_l_min', \n",
    "        'acc_z_dashboard_l_min', 'speed_min', 'gyro_x_dashboard_l_min', \n",
    "        'gyro_y_dashboard_l_min', 'gyro_z_dashboard_l_min', \n",
    "        'timestamp_mean', 'acc_x_dashboard_l_mean', 'acc_y_dashboard_l_mean', \n",
    "        'acc_z_dashboard_l_mean', 'speed_mean', 'gyro_x_dashboard_l_mean', \n",
    "        'gyro_y_dashboard_l_mean', 'gyro_z_dashboard_l_mean', \n",
    "        'timestamp_STD_', 'acc_x_dashboard_l_STD_', 'acc_y_dashboard_l_STD_', \n",
    "        'acc_z_dashboard_l_STD_', 'speed_STD_', 'gyro_x_dashboard_l_STD_', \n",
    "        'gyro_y_dashboard_l_STD_', 'gyro_z_dashboard_l_STD_',\n",
    "         'acc_x_dashboard_l_jerk', 'acc_y_dashboard_l_jerk', \n",
    "        'acc_z_dashboard_l_jerk', 'speed_jerk', 'gyro_x_dashboard_l_jerk', \n",
    "        'gyro_y_dashboard_l_jerk', 'gyro_z_dashboard_l_jerk'\n",
    "    ]\n",
    "    df.columns = new_column_names\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#let's define a window\n",
    "def computeWindow(name,df, windowSize=100):\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"computing dataset {name}\")\n",
    "    #define empty dataframe  \n",
    "    windowed_df=pd.DataFrame()\n",
    "\n",
    "    #define starting and ending index\n",
    "    for start_idx in range(len(df)-windowSize+1):\n",
    "        end_idx=start_idx+windowSize\n",
    "\n",
    "        #extract rows belonging to the window\n",
    "        window=df.iloc[start_idx:end_idx]\n",
    "\n",
    "        #take beginning timestamp and ending timestamp\n",
    "        start_timestamp=window.iloc[0,0]\n",
    "        end_timestamp=window.iloc[-1,0]\n",
    "\n",
    "        \n",
    "        #keep only sensor data\n",
    "        sensor_data_window=window.iloc[:,1:]\n",
    "\n",
    "        #compute metrics for the specific window\n",
    "        max_values=window.max()\n",
    "        min_values=window.min()\n",
    "        mean_values=window.mean()\n",
    "        std_values=window.std()\n",
    "        jerk_values=(sensor_data_window.iloc[-1]-sensor_data_window.iloc[0])/(end_timestamp-start_timestamp)\n",
    "\n",
    "        #concate them (place side by side)\n",
    "        new_row=pd.concat([max_values,min_values,mean_values,std_values,jerk_values])\n",
    "        new_row = new_row.to_frame().T \n",
    "\n",
    "        windowed_df = pd.concat([windowed_df, new_row], ignore_index=True)\n",
    "\n",
    "        if start_idx%10000==0:\n",
    "            print(start_idx)\n",
    "            \n",
    "            \n",
    "    return delete_timestamp(update_name(windowed_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607d3e39-d911-4d3d-91d4-e3d8b40f32d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "computing dataset pvs1_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "--------------------------\n",
      "computing dataset pvs2_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "--------------------------\n",
      "computing dataset pvs3_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs4_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "--------------------------\n",
      "computing dataset pvs5_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "--------------------------\n",
      "computing dataset pvs6_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs7_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "--------------------------\n",
      "computing dataset pvs8_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "--------------------------\n",
      "computing dataset pvs9_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "#winodew the datasets\n",
    "datasets_windowed={name:computeWindow(name,datasets_reduced[name]) for name in datasets.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3c56f5a3-db03-410f-9e9b-0b6cc8f4c48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_max</th>\n",
       "      <th>acc_x_dashboard_l_max</th>\n",
       "      <th>acc_y_dashboard_l_max</th>\n",
       "      <th>acc_z_dashboard_l_max</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>gyro_x_dashboard_l_max</th>\n",
       "      <th>gyro_y_dashboard_l_max</th>\n",
       "      <th>gyro_z_dashboard_l_max</th>\n",
       "      <th>timestamp_min</th>\n",
       "      <th>acc_x_dashboard_l_min</th>\n",
       "      <th>...</th>\n",
       "      <th>gyro_x_dashboard_l_STD_</th>\n",
       "      <th>gyro_y_dashboard_l_STD_</th>\n",
       "      <th>gyro_z_dashboard_l_STD_</th>\n",
       "      <th>acc_x_dashboard_l_jerk</th>\n",
       "      <th>acc_y_dashboard_l_jerk</th>\n",
       "      <th>acc_z_dashboard_l_jerk</th>\n",
       "      <th>speed_jerk</th>\n",
       "      <th>gyro_x_dashboard_l_jerk</th>\n",
       "      <th>gyro_y_dashboard_l_jerk</th>\n",
       "      <th>gyro_z_dashboard_l_jerk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.037529</td>\n",
       "      <td>9.891764</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>0.173187</td>\n",
       "      <td>0.193024</td>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>-0.065481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.088113</td>\n",
       "      <td>0.093786</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>0.017836</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.015413</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>-0.003853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.037529</td>\n",
       "      <td>9.891764</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>0.173187</td>\n",
       "      <td>0.193024</td>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>-0.065481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092079</td>\n",
       "      <td>0.088097</td>\n",
       "      <td>0.093472</td>\n",
       "      <td>0.004686</td>\n",
       "      <td>-0.001058</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.036606</td>\n",
       "      <td>-0.052019</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.037529</td>\n",
       "      <td>9.891764</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>0.119781</td>\n",
       "      <td>0.193024</td>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>-0.065481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091987</td>\n",
       "      <td>0.086446</td>\n",
       "      <td>0.093455</td>\n",
       "      <td>-0.000756</td>\n",
       "      <td>-0.004232</td>\n",
       "      <td>-0.002570</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.055872</td>\n",
       "      <td>-0.059725</td>\n",
       "      <td>-0.009633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.037529</td>\n",
       "      <td>9.891764</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>0.119781</td>\n",
       "      <td>0.193024</td>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>-0.065481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089988</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.093497</td>\n",
       "      <td>-0.006348</td>\n",
       "      <td>-0.014208</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.011560</td>\n",
       "      <td>-0.046239</td>\n",
       "      <td>-0.015413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>0.021308</td>\n",
       "      <td>0.037529</td>\n",
       "      <td>9.891764</td>\n",
       "      <td>0.009432</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>0.119781</td>\n",
       "      <td>0.193024</td>\n",
       "      <td>1.577223e+09</td>\n",
       "      <td>-0.065481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090007</td>\n",
       "      <td>0.084997</td>\n",
       "      <td>0.094386</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.023119</td>\n",
       "      <td>-0.023119</td>\n",
       "      <td>-0.007706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp_max  acc_x_dashboard_l_max  acc_y_dashboard_l_max  \\\n",
       "0   1.577223e+09               0.021308               0.037529   \n",
       "1   1.577223e+09               0.021308               0.037529   \n",
       "2   1.577223e+09               0.021308               0.037529   \n",
       "3   1.577223e+09               0.021308               0.037529   \n",
       "4   1.577223e+09               0.021308               0.037529   \n",
       "\n",
       "   acc_z_dashboard_l_max  speed_max  gyro_x_dashboard_l_max  \\\n",
       "0               9.891764   0.009432                0.304222   \n",
       "1               9.891764   0.009432                0.304222   \n",
       "2               9.891764   0.009432                0.304222   \n",
       "3               9.891764   0.009432                0.304222   \n",
       "4               9.891764   0.009432                0.304222   \n",
       "\n",
       "   gyro_y_dashboard_l_max  gyro_z_dashboard_l_max  timestamp_min  \\\n",
       "0                0.173187                0.193024   1.577223e+09   \n",
       "1                0.173187                0.193024   1.577223e+09   \n",
       "2                0.119781                0.193024   1.577223e+09   \n",
       "3                0.119781                0.193024   1.577223e+09   \n",
       "4                0.119781                0.193024   1.577223e+09   \n",
       "\n",
       "   acc_x_dashboard_l_min  ...  gyro_x_dashboard_l_STD_  \\\n",
       "0              -0.065481  ...                 0.091692   \n",
       "1              -0.065481  ...                 0.092079   \n",
       "2              -0.065481  ...                 0.091987   \n",
       "3              -0.065481  ...                 0.089988   \n",
       "4              -0.065481  ...                 0.090007   \n",
       "\n",
       "   gyro_y_dashboard_l_STD_  gyro_z_dashboard_l_STD_  acc_x_dashboard_l_jerk  \\\n",
       "0                 0.088113                 0.093786               -0.000302   \n",
       "1                 0.088097                 0.093472                0.004686   \n",
       "2                 0.086446                 0.093455               -0.000756   \n",
       "3                 0.085906                 0.093497               -0.006348   \n",
       "4                 0.084997                 0.094386                0.003628   \n",
       "\n",
       "   acc_y_dashboard_l_jerk  acc_z_dashboard_l_jerk  speed_jerk  \\\n",
       "0               -0.000302                0.017836    0.000246   \n",
       "1               -0.001058               -0.001663    0.000246   \n",
       "2               -0.004232               -0.002570    0.000246   \n",
       "3               -0.014208                0.006651    0.000246   \n",
       "4               -0.000605               -0.000605    0.000246   \n",
       "\n",
       "   gyro_x_dashboard_l_jerk  gyro_y_dashboard_l_jerk  gyro_z_dashboard_l_jerk  \n",
       "0                -0.015413                 0.001927                -0.003853  \n",
       "1                -0.036606                -0.052019                 0.001927  \n",
       "2                -0.055872                -0.059725                -0.009633  \n",
       "3                -0.011560                -0.046239                -0.015413  \n",
       "4                 0.023119                -0.023119                -0.007706  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_windowed[\"pvs3_gps_mpu\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f55c0-7ad3-4152-8d20-499523477b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269336, 36)\n"
     ]
    }
   ],
   "source": [
    "#CONCATENATE ALL OF THEM AND FIND THE FINAL DATASET \n",
    "combined_df = pd.concat(datasets_windowed_final.values(), axis=0, ignore_index=True)\n",
    "\n",
    "combined_df.head()\n",
    "#combined_df.size()\n",
    "print(type(combined_df))\n",
    "print(combined_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d90959-dd53-4b47-8397-e475df0708dd",
   "metadata": {},
   "source": [
    "## WORK AGAIN ON CORRELATION (NOW INTERESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b105e3-acbd-4028-939c-e859b3584097",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_final=compute_correlation(combined_df,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b652a27-8f90-4e2a-8333-fddcfe8283d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated(df,corr,threshold=0.9):\n",
    "    #take absoulute values\n",
    "    corr_matrix_abs=corr.abs()\n",
    "    \n",
    "    #take only upper diagonal \n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "    \n",
    "    highly_correlated_features=np.where(corr_matrix_abs*mask>threshold)\n",
    "    \n",
    "    #print and store highly correlated features\n",
    "    \n",
    "    to_drop=set()\n",
    "    for i,j in zip(*highly_correlated_features):\n",
    "        #print( f\"highly correlated pair: {corr_matrix_abs.columns[i]}-{corr_matrix_abs.columns[j]},(correlation: {corr_matrix_abs.iloc[i, j]:.2f})\")\n",
    "        to_drop.add(corr_matrix_abs.columns[j])\n",
    "        #print(corr_matrix_abs.columns[j])\n",
    "    \n",
    "    #remove to_drop columns\n",
    "    cleaned_df=df.drop(columns=to_drop)\n",
    "    print(f\"droopped columns {to_drop}\")\n",
    "    #print(f\"removed {count} columns\")\n",
    "    print(f\"new dataframe has shape {cleaned_df.shape}\")\n",
    "\n",
    "    return cleaned_df,to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "875a187d-84bb-4a72-9db9-b833e0264604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "droopped columns {'speed_min', 'gyro_y_dashboard_l_max', 'gyro_y_dashboard_l_STD_', 'acc_z_dashboard_l_STD_', 'gyro_x_dashboard_l_max', 'gyro_z_dashboard_l_mean', 'acc_z_dashboard_l_max', 'acc_x_dashboard_l_STD_', 'acc_y_dashboard_l_STD_', 'acc_y_dashboard_l_max', 'acc_x_dashboard_l_min', 'gyro_x_dashboard_l_min', 'speed_mean', 'acc_z_dashboard_l_min', 'acc_y_dashboard_l_min', 'gyro_y_dashboard_l_min', 'gyro_x_dashboard_l_STD_'}\n",
      "new dataframe has shape (269336, 19)\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\bruker\\AppData\\Local\\Temp\\ipykernel_38728\\2447120228.py\", line 3, in <module>\n",
      "    final_metrics_correlation = {name: compute_correlation(cleaned_final_df[name]) for name in cleaned_final_df.columns}\n",
      "  File \"C:\\Users\\bruker\\AppData\\Local\\Temp\\ipykernel_38728\\2447120228.py\", line 3, in <dictcomp>\n",
      "    final_metrics_correlation = {name: compute_correlation(cleaned_final_df[name]) for name in cleaned_final_df.columns}\n",
      "  File \"C:\\Users\\bruker\\AppData\\Local\\Temp\\ipykernel_38728\\3691109450.py\", line 2, in compute_correlation\n",
      "    numeric_df = df.select_dtypes(include=['number'])\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\pandas\\core\\generic.py\", line 5575, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "AttributeError: 'Series' object has no attribute 'select_dtypes'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1115, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"c:\\Users\\bruker\\venv\\lib\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "cleaned_final_df, dropped_columns = remove_highly_correlated(combined_df, corr_matrix_final, 0.6)\n",
    "\n",
    "final_metrics_correlation = {name: compute_correlation(cleaned_final_df[name]) for name in cleaned_final_df.columns}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
