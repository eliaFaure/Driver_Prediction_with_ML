{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import make_scorer, accuracy_score \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for merging left and right dataframe\n",
    "def merge(left, right, name ):\n",
    "    pvs= pd.concat([left, right], axis=1)\n",
    "    length= len(left)\n",
    "\n",
    "    # Renaming labels\n",
    "    pvs.columns = [\n",
    "    'timestamp', 'acc_x_dashboard_l', 'acc_y_dashboard_l', 'acc_z_dashboard_l',\n",
    "    'acc_x_above_suspension_l', 'acc_y_above_suspension_l', 'acc_z_above_suspension_l', \n",
    "    'acc_x_below_suspension_l', 'acc_y_below_suspension_l', 'acc_z_below_suspension_l', \n",
    "    'gyro_x_dashboard_l', 'gyro_y_dashboard_l', 'gyro_z_dashboard_l', 'gyro_x_above_suspension_l', \n",
    "    'gyro_y_above_suspension_l', 'gyro_z_above_suspension_l', 'gyro_x_below_suspension_l', \n",
    "    'gyro_y_below_suspension_l', 'gyro_z_below_suspension_l', 'mag_x_dashboard_l', 'mag_y_dashboard_l', \n",
    "    'mag_z_dashboard_l', 'mag_x_above_suspension_l', 'mag_y_above_suspension_l', 'mag_z_above_suspension_l', \n",
    "    'temp_dashboard_l', 'temp_above_suspension_l', 'temp_below_suspension_l', 'timestamp_gps', \n",
    "    'latitude', 'longitude', 'speed', 'timestamp', 'acc_x_dashboard_r', 'acc_y_dashboard_r', \n",
    "    'acc_z_dashboard_r', 'acc_x_above_suspension_r', 'acc_y_above_suspension_r', \n",
    "    'acc_z_above_suspension_r', 'acc_x_below_suspension_r', 'acc_y_below_suspension_r', \n",
    "    'acc_z_below_suspension_r', 'gyro_x_dashboard_r', 'gyro_y_dashboard_r', 'gyro_z_dashboard_r', \n",
    "    'gyro_x_above_suspension_r', 'gyro_y_above_suspension_r', 'gyro_z_above_suspension_r', \n",
    "    'gyro_x_below_suspension_r', 'gyro_y_below_suspension_r', 'gyro_z_below_suspension_r', \n",
    "    'mag_x_dashboard_r', 'mag_y_dashboard_r', 'mag_z_dashboard_r', 'mag_x_above_suspension_r', \n",
    "    'mag_y_above_suspension_r', 'mag_z_above_suspension_r', 'temp_dashboard_r', 'temp_above_suspension_r', \n",
    "    'temp_below_suspension_r', 'timestamp_gps', 'latitude', 'longitude', 'speed'\n",
    "    ]\n",
    "    \n",
    "\n",
    "    # Remove duplicate columns (those with the same name, e.g., 'timestamp_gps', 'latitude', etc.)\n",
    "    pvs_removed = pvs.loc[:, ~pvs.columns.duplicated()]\n",
    "\n",
    "    # Columns to keep. We try these first\n",
    "    to_keep=[\"timestamp\",\n",
    "             \"acc_x_dashboard_l\",\n",
    "             \"acc_y_dashboard_l\",\n",
    "             \"acc_z_dashboard_l\",\n",
    "             \"speed\",\n",
    "             \"gyro_x_dashboard_l\",\n",
    "             \"gyro_y_dashboard_l\",\n",
    "             \"gyro_z_dashboard_l\"\n",
    "            ]\n",
    "    \n",
    "    pvs_removed=pvs_removed[to_keep]\n",
    "\n",
    "    #create the driver column ( target )\n",
    "    if name in (\"pvs1_gps_mpu\",\"pvs2_gps_mpu\",\"pvs3_gps_mpu\"):\n",
    "        pvs_removed['Driver'] = 1\n",
    "    elif name in (\"pvs4_gps_mpu\",\"pvs5_gps_mpu\",\"pvs6_gps_mpu\"):\n",
    "        pvs_removed['Driver'] = 2\n",
    "    else: \n",
    "        pvs_removed['Driver'] = 3\n",
    "        \n",
    "    return pvs_removed\n",
    "\n",
    "#Drivers do not drive in the start and end of each route. Function for removing these indicies\n",
    "def remove_zero_values(dfs):\n",
    "\n",
    "    new = dfs\n",
    "\n",
    "    non_zero_indices = {}\n",
    "    threshold = 0.1  # Define the threshold to detect non-zero speeds\n",
    "\n",
    "    for key, df in new.items():\n",
    "\n",
    "        first_non_zero_index = (df['speed'].abs() > threshold).idxmax()\n",
    "        last_non_zero_index = (df['speed'][::-1].abs() > threshold).idxmax()\n",
    "\n",
    "        non_zero_indices[key] = (first_non_zero_index, last_non_zero_index)\n",
    "\n",
    "    # Iterate through each dataset and its respective non-zero index\n",
    "    for key, index in non_zero_indices.items():\n",
    "        new[key] = new[key].iloc[index[0]:index[1]].reset_index(drop=True)  # Remove rows up to the index and reset index\n",
    "\n",
    "    return new\n",
    "\n",
    "#Function for making dfs equal size in order to avoid bias. Each route is truncated to the same length\n",
    "def equalize_dfs(dfs):\n",
    "\n",
    "    new = dfs\n",
    "\n",
    "    # Split DataFrames into three routes\n",
    "    dfs_keys = list(new.keys())  # Get all keys in the dictionary\n",
    "    first_route_keys = dfs_keys[:3]  # First three keys for the first route\n",
    "    second_route_keys = dfs_keys[3:6]  # Next three keys for the second route\n",
    "    third_route_keys = dfs_keys[6:]  # Last three keys for the third route\n",
    "\n",
    "    # Calculate the minimum lengths for each route\n",
    "    min_length_first_route = min(len(new[key]) for key in first_route_keys)\n",
    "    min_length_second_route = min(len(new[key]) for key in second_route_keys)\n",
    "    min_length_third_route = min(len(new[key]) for key in third_route_keys)\n",
    "\n",
    "    # Truncate all DataFrames in each route to the respective minimum length\n",
    "    for key in first_route_keys:\n",
    "        new[key] = new[key].iloc[:min_length_first_route].reset_index(drop=True)\n",
    "\n",
    "    for key in second_route_keys:\n",
    "        new[key] = new[key].iloc[:min_length_second_route].reset_index(drop=True)\n",
    "\n",
    "    for key in third_route_keys:\n",
    "        new[key] = new[key].iloc[:min_length_third_route].reset_index(drop=True)\n",
    "\n",
    "    return new\n",
    "\n",
    "#Need to make the ratio between dfs and ratio to be an integer in order for dataframe reduction to work\n",
    "def round_dfs(dfs, ratio):\n",
    "\n",
    "    new = dfs\n",
    "\n",
    "    for key, df in new.items():\n",
    "\n",
    "        rounded_length = len(df) - (len(df) % ratio)\n",
    "\n",
    "        new[key] = df.iloc[:rounded_length].reset_index(drop=True)\n",
    "\n",
    "    return new\n",
    "\n",
    "\n",
    "def reduce_df(df, ratio, name):\n",
    "    new = pd.DataFrame()\n",
    "    print(f\"Reducing {name}\")\n",
    "    \n",
    "    # Iterate in steps of 'ratio' through the DataFrame\n",
    "    for i in range(0, len(df) - ratio + 1, ratio):\n",
    "        # Select the rows from i to i+ratio (inclusive of i, exclusive of i+ratio)\n",
    "        subset = df.iloc[i:i+ratio]\n",
    "        \n",
    "        # Calculate the mean for each column in the selected rows\n",
    "        merged_row = subset.mean(axis=0)\n",
    "        \n",
    "        # Append the result as a new row to the DataFrame `new`\n",
    "        new = pd.concat([new, merged_row.to_frame().T], ignore_index=True)\n",
    "        \n",
    "    return new\n",
    "\n",
    "\n",
    "#helping function for reduction\n",
    "\n",
    "def delete_timestamp(df):\n",
    "    to_remove=[\"timestamp_max\",\"timestamp_min\",\"timestamp_mean\",\"timestamp_STD_\"]\n",
    "    new= df.drop(columns=to_remove, axis=1, errors='ignore')\n",
    "\n",
    "    return new\n",
    "\n",
    "def update_name(df):\n",
    "    new_column_names = [ 'timestamp_max','acc_x_dashboard_l_max', 'acc_y_dashboard_l_max', \n",
    "        'acc_z_dashboard_l_max', 'speed_max', 'gyro_x_dashboard_l_max', \n",
    "        'gyro_y_dashboard_l_max', 'gyro_z_dashboard_l_max', \n",
    "        'timestamp_min', 'acc_x_dashboard_l_min', 'acc_y_dashboard_l_min', \n",
    "        'acc_z_dashboard_l_min', 'speed_min', 'gyro_x_dashboard_l_min', \n",
    "        'gyro_y_dashboard_l_min', 'gyro_z_dashboard_l_min', \n",
    "        'timestamp_mean', 'acc_x_dashboard_l_mean', 'acc_y_dashboard_l_mean', \n",
    "        'acc_z_dashboard_l_mean', 'speed_mean', 'gyro_x_dashboard_l_mean', \n",
    "        'gyro_y_dashboard_l_mean', 'gyro_z_dashboard_l_mean', \n",
    "        'timestamp_STD_', 'acc_x_dashboard_l_STD_', 'acc_y_dashboard_l_STD_', \n",
    "        'acc_z_dashboard_l_STD_', 'speed_STD_', 'gyro_x_dashboard_l_STD_', \n",
    "        'gyro_y_dashboard_l_STD_', 'gyro_z_dashboard_l_STD_']\n",
    "        #,\n",
    "        # 'acc_x_dashboard_l_jerk', 'acc_y_dashboard_l_jerk', \n",
    "        #'acc_z_dashboard_l_jerk', 'speed_jerk', 'gyro_x_dashboard_l_jerk', \n",
    "        #'gyro_y_dashboard_l_jerk', 'gyro_z_dashboard_l_jerk'\n",
    "        #]\n",
    "    df.columns = new_column_names\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#function for computing the rolling window and the aggregation functions, \n",
    "#--> returns a dictionary containing the 9 dataframes windowed (still separated)\n",
    "def computeWindow(name,df, windowSize=100, show=False):\n",
    "    if show:\n",
    "        print(\"--------------------------\")\n",
    "        print(f\"computing dataset {name}\")\n",
    "    \n",
    "    #define empty dataframe  \n",
    "\n",
    "    X= df.iloc[:, :-1]\n",
    "    Y= df.iloc[:len(df)-windowSize+1, -1]\n",
    "    windowed_df=pd.DataFrame()\n",
    "\n",
    "    #define starting and ending index\n",
    "    for start_idx in range(len(df)-windowSize+1):\n",
    "        end_idx=start_idx+windowSize\n",
    "\n",
    "        #extract rows belonging to the window\n",
    "        window=X.iloc[start_idx:end_idx]\n",
    "\n",
    "        #take beginning timestamp and ending timestamp\n",
    "        start_timestamp=window.iloc[0,0]\n",
    "        end_timestamp=window.iloc[-1,0]\n",
    "\n",
    "        \n",
    "        #keep only sensor data\n",
    "        sensor_data_window=window.iloc[:,1:]\n",
    "\n",
    "        #compute metrics for the specific window\n",
    "        max_values=window.max()\n",
    "        min_values=window.min()\n",
    "        mean_values=window.mean()\n",
    "        std_values=window.std()\n",
    "        #jerk_values=(sensor_data_window.iloc[-1]-sensor_data_window.iloc[0])/(end_timestamp-start_timestamp)\n",
    "\n",
    "        #concate them (place side by side)\n",
    "        new_row=pd.concat([max_values,min_values,mean_values,std_values,])#jerk_values])\n",
    "        new_row = new_row.to_frame().T \n",
    "\n",
    "        windowed_df = pd.concat([windowed_df, new_row], ignore_index=True)\n",
    "\n",
    "        \n",
    "        if show and start_idx%10000==0:\n",
    "            print(start_idx)\n",
    "\n",
    "    #place aside again  X and Y\n",
    "    final=pd.concat([delete_timestamp(update_name(windowed_df)),Y], axis=1)  \n",
    "    return final\n",
    "\n",
    "\n",
    "#define train_test splits, based on the track we define in test_track. \n",
    "#we use test_track for testing and the other two tracks for training\n",
    "#-->returns X_train,y_train,X_test,y_test as numpy arrays\n",
    "\n",
    "def train_test_my_split(dfs,test_track,numpy_conversion=False):\n",
    "    #take track three for testing and trcakk 1,2 for trainig\n",
    "    all_keys=list(dfs.keys())\n",
    "\n",
    "    if test_track==3:\n",
    "        train_indices=[0,1,3,4,6,7]\n",
    "        test_indices=[2,5,8]\n",
    "    elif test_track==2:\n",
    "        train_indices=[0,2,3,5,6,8]\n",
    "        test_indices=[1,4,7]\n",
    "    elif test_track==1:\n",
    "        train_indices=[1,2,4,5,7,8]\n",
    "        test_indices=[0,3,6]\n",
    "        \n",
    "\n",
    "    train_dfs = [dfs[all_keys[i]] for i in train_indices]\n",
    "    train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    # Shuffle the training data\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    test_dfs = [dfs[all_keys[i]] for i in test_indices]\n",
    "    test_df = pd.concat(test_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    \n",
    "    # Shuffle testing data\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    if numpy_conversion:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1].to_numpy()\n",
    "        y_train=train_df.iloc[:,-1].to_numpy()\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1].to_numpy()\n",
    "        y_test=test_df.iloc[:,-1].to_numpy()\n",
    "    else:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1]\n",
    "        y_train=train_df.iloc[:,-1]\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1]\n",
    "        y_test=test_df.iloc[:,-1]\n",
    "        \n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "#function for creating the model based on the parameter type\n",
    "#--> returns the model\n",
    "def create_model(type):\n",
    "    if type==\"RandomForest\":\n",
    "        return RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif type == \"SVM\":\n",
    "        return SVC(kernel=\"rbf\", C=1.0)\n",
    "    elif type == \"lr\":\n",
    "        return LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "#test the model on the TEST set, take as input the NON-WINDOWED datasets\n",
    "#-->returns the accuracy on the test set\n",
    "\n",
    "def test_model(X_train,y_train,X_test,y_test,model_type,test_track=3):\n",
    "    #create the  model \n",
    "    model=create_model(model_type)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "\n",
    "# function for cross-fold evaluation, with num_folds folds, taken as a parameter\n",
    "#--> returns average accuracy for the specific hyperparameters configuration defined as input\n",
    "\n",
    "def evaluate_model(X_train,y_train,model_type,num_folds,test_track=3):\n",
    "    \n",
    "    #create the  model \n",
    "    model=create_model(model_type)\n",
    "\n",
    "    #APPLY CROSS-FOLDER EVALUATION\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_ttrain, X_val = X_train[train_index], X_train[val_index] \n",
    "        y_ttrain, y_val = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "        model.fit(X_ttrain, y_ttrain) \n",
    "        y_pred = model.predict(X_val) \n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_pred) \n",
    "        print((y_val != y_pred).sum())\n",
    "        print('accuracy:', accuracy)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = sum(fold_accuracies) / num_folds\n",
    "    print('average of fold',average_accuracy)\n",
    "\n",
    "    return average_accuracy\n",
    "\n",
    "#intermediate function, used for: \n",
    "#windowing based on the window size\n",
    "#-->returns X_train,y_train,X_test,y_test based on track defined in test_track\n",
    "\n",
    "\n",
    "def window_and_split(dfs,window_size,test_track=3):\n",
    "    dfs_windowed={name:computeWindow(name,dfs[name]) for name in dfs.keys()}\n",
    "\n",
    "    return train_test_my_split(dfs_windowed,test_track)\n",
    "\n",
    "#main function, takes hyperparameters options, model type and num_folds for k-fold\n",
    "#tries all configurations on the evaluation set\n",
    "#test the best configuration on the trainig set \n",
    "\n",
    "def tuning_and_evaluation(dfs,window_sizes,model_type,num_folds,test_track=3):\n",
    "\n",
    "    #initialize optimal results\n",
    "    best_accuracy=0\n",
    "    best_window_size=0\n",
    "\n",
    "\n",
    "    #store all the average accuracies with different hyperparameters inside an arrray\n",
    "    tot_accuracies=[]\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        print(f\"--------------------\")\n",
    "        print(f\"EVALUATE window_size: {window_size}\")\n",
    "        \n",
    "        X_train,y_train,X_test,y_test=window_and_split(datasets_reduced,window_size)\n",
    "        \n",
    "        accuracy=evaluate_model(X_train,y_train,model_type,num_folds,test_track)\n",
    "        tot_accuracies.append(accuracy)\n",
    "        \n",
    "        \n",
    "        #update optimal results if needed\n",
    "        if accuracy>best_accuracy:\n",
    "            best_accuracy=accuracy\n",
    "            best_window_size=window_size\n",
    "            \n",
    "            \n",
    "    print(f\"Best window size: {best_window_size} with accuracy: {best_accuracy}\")\n",
    "    print(\"test best model on TEST data\")\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=window_and_split(datasets_reduced,best_window_size)\n",
    "    \n",
    "    test_model(X_train,y_train,X_test,y_test,model_type,test_track)\n",
    "\n",
    "# Intended to include cross-validation and usage of different window sizes\n",
    "\n",
    "def tuning_and_evaluation_correlation(dfs,window_sizes,model_type,num_folds,dropped_features, test_track=3):\n",
    "\n",
    "    #initialize optimal results\n",
    "    best_accuracy=0\n",
    "    best_window_size=0\n",
    "\n",
    "    #store all the average accuracies with different hyperparameters inside an arrray\n",
    "    tot_accuracies=[]\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        print(f\"--------------------\")\n",
    "        print(f\"EVALUATE window_size: {window_size}\")\n",
    "        \n",
    "        X_train,y_train,X_test,y_test=window_and_split(dfs,window_size)\n",
    "\n",
    "        X_train_reduced=X_train.drop(columns=dropped_features)\n",
    "        X_test_reduced=X_test.drop(columns=dropped_features)\n",
    "        \n",
    "        accuracy=evaluate_model(X_train_reduced.to_numpy(),y_train.to_numpy(),model_type,num_folds,test_track)\n",
    "        tot_accuracies.append(accuracy)\n",
    "        \n",
    "        #update optimal results if needed\n",
    "        if accuracy>best_accuracy:\n",
    "            best_accuracy=accuracy\n",
    "            best_window_size=window_size\n",
    "            \n",
    "            \n",
    "    print(f\"Best window size: {best_window_size} with accuracy: {best_accuracy}\")\n",
    "    print(\"test best model on TEST data\")\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=window_and_split(dfs,best_window_size)\n",
    "\n",
    "    X_train_reduced=X_train.drop(columns=dropped_features)\n",
    "    X_test_reduced=X_test.drop(columns=dropped_features)\n",
    "    \n",
    "    test_model(X_train_reduced,y_train,X_test_reduced,y_test,model_type,test_track)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datasets\n",
    "filepaths_left={\n",
    "    \"pvs1_gps_mpu\" : r\"../archive/PVS 1/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs2_gps_mpu\" : r\"../archive/PVS 2/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs3_gps_mpu\" : r\"../archive/PVS 3/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs4_gps_mpu\" : r\"../archive/PVS 4/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs5_gps_mpu\" : r\"../archive/PVS 5/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs6_gps_mpu\" : r\"../archive/PVS 6/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs7_gps_mpu\" : r\"../archive/PVS 7/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs8_gps_mpu\" : r\"../archive/PVS 8/dataset_gps_mpu_left.csv\",\n",
    "    \"pvs9_gps_mpu\" : r\"../archive/PVS 9/dataset_gps_mpu_left.csv\"\n",
    "}\n",
    "\n",
    "filepaths_right={\n",
    "    \"pvs1_gps_mpu\" : r\"../archive/PVS 1/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs2_gps_mpu\" : r\"../archive/PVS 2/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs3_gps_mpu\" : r\"../archive/PVS 3/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs4_gps_mpu\" : r\"../archive/PVS 4/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs5_gps_mpu\" : r\"../archive/PVS 5/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs6_gps_mpu\" : r\"../archive/PVS 6/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs7_gps_mpu\" : r\"../archive/PVS 7/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs8_gps_mpu\" : r\"../archive/PVS 8/dataset_gps_mpu_right.csv\",\n",
    "    \"pvs9_gps_mpu\" : r\"../archive/PVS 9/dataset_gps_mpu_right.csv\"\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Left and right corresponds to sensordata from either side of the cars\n",
    "datasets_left = {name:pd.read_csv(path) for name,path in filepaths_left.items()}\n",
    "datasets_right = {name:pd.read_csv(path) for name,path in filepaths_right.items()}\n",
    "\n",
    "datasets = {name: merge(datasets_left[name],datasets_right[name], name) for name in datasets_right.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_rm_zeros = remove_zero_values(datasets)\n",
    "equalized_datasets = equalize_dfs(datasets_rm_zeros)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDUCE THE DATA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing pvs1_gps_mpu\n",
      "Reducing pvs2_gps_mpu\n",
      "Reducing pvs3_gps_mpu\n",
      "Reducing pvs4_gps_mpu\n",
      "Reducing pvs5_gps_mpu\n",
      "Reducing pvs6_gps_mpu\n",
      "Reducing pvs7_gps_mpu\n",
      "Reducing pvs8_gps_mpu\n",
      "Reducing pvs9_gps_mpu\n"
     ]
    }
   ],
   "source": [
    "#REDUCE THE DATA\n",
    "ratio=4\n",
    "rounded_datasets = round_dfs(equalized_datasets, ratio)\n",
    "\n",
    "datasets_reduced={name:reduce_df(rounded_datasets[name],ratio,name) for name in rounded_datasets.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature reduction with correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "computing dataset pvs1_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs2_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs3_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs4_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs5_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs6_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs7_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs8_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n",
      "--------------------------\n",
      "computing dataset pvs9_gps_mpu\n",
      "0\n",
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "test_track=3\n",
    "dfs_windowed={name:computeWindow(name,datasets_reduced[name],100,True) for name in datasets_reduced.keys()}\n",
    "X_train,y_train,X_test,y_test=train_test_my_split(dfs_windowed,test_track,numpy_conversion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This codeblock is only for investigating correlated features. Define training and testing splits again when testing different window sizes\n",
    "\n",
    "#define a function for correlation \n",
    "def compute_correlation(df,plot=False):\n",
    "    # Only compute using the numeric data types in the dataset\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    correlation_matrix=numeric_df.corr()\n",
    "    \n",
    "    return numeric_df, correlation_matrix\n",
    "\n",
    "\n",
    "def remove_highly_correlated(df,corr,threshold=0.9):\n",
    "    #take absoulute values\n",
    "    corr_matrix_abs=corr.abs()\n",
    "    \n",
    "    #take only upper diagonal \n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "    \n",
    "    highly_correlated_features=np.where(corr_matrix_abs*mask>threshold)\n",
    "    \n",
    "    to_drop=set()\n",
    "    for i,j in zip(*highly_correlated_features):\n",
    "        print( f\"highly correlated pair: {corr_matrix_abs.columns[i]}-{corr_matrix_abs.columns[j]},(correlation: {corr_matrix_abs.iloc[i, j]:.2f})\")\n",
    "        to_drop.add(corr_matrix_abs.columns[j])\n",
    "    \n",
    "    #remove to_drop columns\n",
    "    cleaned_df=df.drop(columns=to_drop)\n",
    "\n",
    "    print(f\"new dataframe has shape {cleaned_df.shape}\")\n",
    "\n",
    "    return cleaned_df, to_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highly correlated pair: acc_z_dashboard_l_max-acc_z_dashboard_l_STD_,(correlation: 0.90)\n",
      "highly correlated pair: speed_max-speed_min,(correlation: 0.98)\n",
      "highly correlated pair: speed_max-speed_mean,(correlation: 0.99)\n",
      "highly correlated pair: gyro_x_dashboard_l_max-gyro_x_dashboard_l_STD_,(correlation: 0.91)\n",
      "highly correlated pair: gyro_y_dashboard_l_max-gyro_y_dashboard_l_STD_,(correlation: 0.88)\n",
      "highly correlated pair: gyro_z_dashboard_l_max-gyro_z_dashboard_l_mean,(correlation: 0.81)\n",
      "highly correlated pair: acc_z_dashboard_l_min-acc_z_dashboard_l_STD_,(correlation: 0.91)\n",
      "highly correlated pair: speed_min-speed_mean,(correlation: 0.99)\n",
      "highly correlated pair: gyro_x_dashboard_l_min-gyro_x_dashboard_l_STD_,(correlation: 0.89)\n",
      "highly correlated pair: gyro_y_dashboard_l_min-gyro_y_dashboard_l_STD_,(correlation: 0.89)\n",
      "highly correlated pair: acc_x_dashboard_l_STD_-gyro_y_dashboard_l_STD_,(correlation: 0.89)\n",
      "new dataframe has shape (137500, 22)\n"
     ]
    }
   ],
   "source": [
    "test_track=3\n",
    "numeric_df, corr_matrix = compute_correlation(X_train)\n",
    "new_not_correlated, dropped_features = remove_highly_correlated(X_train,corr_matrix,threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced=X_train.drop(columns=dropped_features)\n",
    "X_test_reduced=X_test.drop(columns=dropped_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code block quickly checks accuracies using training and test sets, but not cross-validation\n",
    "\n",
    "print(\"fitting model\")\n",
    "model =create_model(\"lr\")\n",
    "model.fit(X_train_reduced,y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train_reduced)\n",
    "y_test_pred = model.predict(X_test_reduced)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Train set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuning_and_evaluation_correlation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m num_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      4\u001b[0m test_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtuning_and_evaluation_correlation\u001b[49m(datasets_reduced,window_sizes,model_type,num_folds,dropped_features,test_track)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tuning_and_evaluation_correlation' is not defined"
     ]
    }
   ],
   "source": [
    "model_type=\"lr\"\n",
    "window_sizes=[100,500]\n",
    "num_folds = 5\n",
    "test_track=3\n",
    "\n",
    "tuning_and_evaluation_correlation(datasets_reduced,window_sizes,model_type,num_folds,dropped_features,test_track)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
