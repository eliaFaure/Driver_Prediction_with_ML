{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec03935-e373-428f-a845-66a34c0219ad",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL AND EVALUATE IT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ec4a13-9fbc-4f6e-9c9d-ea61b2bcbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for code\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import make_scorer, accuracy_score \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d65b83-5b4f-411f-9203-2c3ae02508f3",
   "metadata": {},
   "source": [
    "## DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a14fc20-06cd-4fdb-a8f9-ce3bed23426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train_test splits, based on the track we define in test_track. \n",
    "#we use test_track for testing and the other two tracks for training\n",
    "#-->returns X_train,y_train,X_test,y_test as numpy arrays\n",
    "\n",
    "def train_test_my_split(dfs,test_track,numpy_conversion=True):\n",
    "    #take track three for testing and trcakk 1,2 for trainig\n",
    "    all_keys=list(dfs.keys())\n",
    "\n",
    "\n",
    "    if test_track==3:\n",
    "        train_indices=[0,1,3,4,6,7]\n",
    "        test_indices=[2,5,8]\n",
    "    elif test_track==2:\n",
    "        train_indices=[0,2,3,5,6,8]\n",
    "        test_indices=[1,4,7]\n",
    "    elif test_track==1:\n",
    "        train_indices=[1,2,4,5,7,8]\n",
    "        test_indices=[0,3,6]\n",
    "        \n",
    "\n",
    "    train_dfs = [dfs[all_keys[i]] for i in train_indices]\n",
    "    train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    # Shuffle the training data\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    test_dfs = [dfs[all_keys[i]] for i in test_indices]\n",
    "    test_df = pd.concat(test_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    \n",
    "    # Shuffle testing data\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    #split features and targets\n",
    "    if numpy_conversion:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1].to_numpy()\n",
    "        y_train=train_df.iloc[:,-1].to_numpy()\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1].to_numpy()\n",
    "        y_test=test_df.iloc[:,-1].to_numpy()\n",
    "    else:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1]\n",
    "        y_train=train_df.iloc[:,-1]\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1]\n",
    "        y_test=test_df.iloc[:,-1]\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "#function for creating the model based on the parameter type\n",
    "#--> returns the model\n",
    "def create_model(type):\n",
    "    if type==\"RandomForest\":\n",
    "        return RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif type == \"SVM\":\n",
    "        return SVC(kernel=\"rbf\", C=1.0)\n",
    "    elif type == \"lr\":\n",
    "        return LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "#test the model on the TEST set, take as input the NON-WINDOWED datasets\n",
    "#-->returns the accuracy on the test set\n",
    "\n",
    "def test_model(X_train,y_train,X_test,y_test,model_type,test_track=3):\n",
    "    #create the  model \n",
    "    model=create_model(model_type)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "\n",
    "# function for cross-fold evaluation, with num_folds folds, taken as a parameter\n",
    "#--> returns average accuracy for the specific hyperparameters configuration defined as input\n",
    "\n",
    "def evaluate_model(X_train,y_train,model_type,num_folds,test_track=3):\n",
    "    \n",
    "    #create the  model \n",
    "    model=create_model(model_type)\n",
    "\n",
    "    #APPLY CROSS-FOLDER EVALUATION\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_ttrain, X_val = X_train[train_index], X_train[val_index] \n",
    "        y_ttrain, y_val = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "        model.fit(X_ttrain, y_ttrain) \n",
    "        y_pred = model.predict(X_val) \n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_pred) \n",
    "        #print((y_val != y_pred).sum())\n",
    "        print('accuracy:', accuracy)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = sum(fold_accuracies) / num_folds\n",
    "    print('average of fold',average_accuracy)\n",
    "\n",
    "    return average_accuracy\n",
    "\n",
    "#intermediate function, used for: \n",
    "#windowing based on the window size\n",
    "#-->returns X_train,y_train,X_test,y_test based on track defined in test_track\n",
    "\n",
    "\n",
    "def window_and_split(dfs,window_size,test_track=3,numpy_conversion=True):\n",
    "    # Load the windowed data\n",
    "    with open(f\"dfs_windowed_{window_size}.pkl\", \"rb\") as file:\n",
    "        dfs_windowed = pickle.load(file)\n",
    "\n",
    "    return train_test_my_split(dfs_windowed,test_track,numpy_conversion)\n",
    "\n",
    "#receives X_train and X_test and returns pca datasets, as numpy arrays.\n",
    "def apply_PCA(X_train,X_test,threshold):\n",
    "    \n",
    "    scaler= StandardScaler()\n",
    "    X_train_scaled_values=scaler.fit_transform(X_train)\n",
    "    X_test_scaled_values=scaler.transform(X_test)\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled_values, columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled_values, columns=X_train.columns)\n",
    "\n",
    "    pca=PCA()\n",
    "\n",
    "    pca=PCA(n_components=threshold, random_state=42)\n",
    "    X_train_pca=pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca=pca.transform(X_test)\n",
    "\n",
    "    return X_train_pca,X_test_pca\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#main function, takes hyperparameters options, model type and num_folds for k-fold\n",
    "#tries all configurations on the evaluation set\n",
    "#test the best configuration on the trainig set \n",
    "\n",
    "def tuning_and_evaluation(dfs,window_sizes,model_type,num_folds,test_track=3,threshold_pca=1):\n",
    "\n",
    "    #method for deciding if we wanna convert or not into numpy, not important\n",
    "    if threshold_pca!=1:\n",
    "        numpy_conversion=False\n",
    "    else:\n",
    "        numpy_conversion=True\n",
    "\n",
    "    \n",
    "    #initialize optimal results\n",
    "    best_accuracy=0\n",
    "    best_window_size=0\n",
    "\n",
    "\n",
    "    #store all the average accuracies with different hyperparameters inside an arrray\n",
    "    tot_accuracies=[]\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "        print(f\"--------------------\")\n",
    "        print(f\"EVALUATE window_size: {window_size}\")\n",
    "        \n",
    "        X_train,y_train,X_test,y_test=window_and_split(datasets_reduced,window_size,test_track,numpy_conversion)\n",
    "\n",
    "        if threshold_pca!=1:\n",
    "            print(\"apply pca for evaluation\")\n",
    "            X_train,X_test=apply_PCA(X_train,X_test,threshold_pca)\n",
    "\n",
    "        \n",
    "        \n",
    "        accuracy=evaluate_model(X_train,y_train,model_type,num_folds,test_track)\n",
    "        tot_accuracies.append(accuracy)\n",
    "        \n",
    "        \n",
    "        #update optimal results if needed\n",
    "        if accuracy>best_accuracy:\n",
    "            best_accuracy=accuracy\n",
    "            best_window_size=window_size\n",
    "            \n",
    "            \n",
    "    print(f\"Best window size: {best_window_size} with accuracy: {best_accuracy}\")\n",
    "    print(\"test best model on TEST data\")\n",
    "\n",
    "    \n",
    "    X_train,y_train,X_test,y_test=window_and_split(datasets_reduced,best_window_size,test_track,numpy_conversion)\n",
    "\n",
    "    if threshold_pca!=1:\n",
    "            print(\"apply pca for TEST\")\n",
    "            X_train,X_test=apply_PCA(X_train,X_test,threshold_pca)\n",
    "    \n",
    "    test_model(X_train,y_train,X_test,y_test,model_type,test_track)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84560ad9-9859-49e8-a33f-d368d43367b9",
   "metadata": {},
   "source": [
    "## IMPORT THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a2a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets_reduced, which is the temporal data truncated\n",
    "with open(\"datasets_reduced.pkl\", \"rb\") as file:\n",
    "    datasets_reduced = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a558e1-b198-415b-ad0b-15e509d9b77b",
   "metadata": {},
   "source": [
    "## TEST THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ada19aa6-4362-4986-8227-f6e3f36b6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "EVALUATE window_size: 100\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "average of fold 1.0\n",
      "--------------------\n",
      "EVALUATE window_size: 200\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "accuracy: 1.0\n",
      "average of fold 1.0\n",
      "Best window size: 100 with accuracy: 1.0\n",
      "test best model on TEST data\n",
      "Test set accuracy: 0.4781\n"
     ]
    }
   ],
   "source": [
    "model_type=\"RandomForest\"\n",
    "window_sizes=[100,200]\n",
    "num_folds = 5\n",
    "test_track=3\n",
    "threshold_pca=1\n",
    "\n",
    "tuning_and_evaluation(datasets_reduced,window_sizes,model_type,num_folds,test_track,threshold_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b7e239-166d-402d-b809-ad22a49c6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test=train_test_my_split(datasets_reduced,test_track,numpy_conversion=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
