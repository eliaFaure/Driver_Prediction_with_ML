{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec03935-e373-428f-a845-66a34c0219ad",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL AND EVALUATE IT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ec4a13-9fbc-4f6e-9c9d-ea61b2bcbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for code\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import make_scorer, accuracy_score \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d65b83-5b4f-411f-9203-2c3ae02508f3",
   "metadata": {},
   "source": [
    "## DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a14fc20-06cd-4fdb-a8f9-ce3bed23426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "#define train_test splits, based on the track we define in test_track. \n",
    "#we use test_track for testing and the other two tracks for training\n",
    "#-->returns X_train,y_train,X_test,y_test as numpy arrays\n",
    "\n",
    "def train_test_with_partial_ciruits_split(dfs,test_track,numpy_conversion=True):\n",
    "    #generate train and test dictionary\n",
    "\n",
    "    keys=list(dfs.keys())\n",
    "\n",
    "    scenario1_indices=[0,3,6]\n",
    "    scenario2_indices=[1,4,7]\n",
    "    scenario3_indices=[2,5,8]\n",
    "\n",
    "    scenario1_keys=[keys[i] for i in scenario1_indices]\n",
    "    scenario2_keys=[keys[i] for i in scenario2_indices]\n",
    "    scenario3_keys=[keys[i] for i in scenario3_indices]\n",
    "\n",
    "    #generate train dictionary(same as before)\n",
    "\n",
    "    \n",
    "\n",
    "    if test_track==3:\n",
    "        train_keys=scenario1_keys+scenario2_keys\n",
    "        test_keys=scenario3_keys\n",
    "    elif test_track==2:\n",
    "        train_keys=scenario1_keys+scenario3_keys\n",
    "        test_keys=scenario2_keys\n",
    "    elif test_track==1:\n",
    "        train_keys=scenario2_keys+scenario3_keys\n",
    "        test_keys=scenario1_keys\n",
    "    \n",
    "    #take the minimum length of the dataframes\n",
    "    min_length = min([len(df) for df in dfs.values()])\n",
    "    eval_size = int(0.4 * min_length)\n",
    "\n",
    "    #take the first eval_size rows for evaluation, consider all dfs\n",
    "    train_ev_dfs = {key: df.iloc[:eval_size] for key, df in dfs.items()}\n",
    "\n",
    "    #concatenate different drivers in the same circuit in the same dataframe\n",
    "\n",
    "    train_ev_dfs_combined = {\n",
    "        \"scenario1\": pd.concat([train_ev_dfs[key] for key in scenario1_keys], axis=0, ignore_index=True),\n",
    "        \"scenario2\": pd.concat([train_ev_dfs[key] for key in scenario2_keys], axis=0, ignore_index=True),\n",
    "        \"scenario3\": pd.concat([train_ev_dfs[key] for key in scenario3_keys], axis=0, ignore_index=True)\n",
    "    }\n",
    "\n",
    "\n",
    "    #shuffle the dataframes\n",
    "    for key, df in train_ev_dfs_combined.items():\n",
    "        train_ev_dfs_combined[key] = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #generate train dictionary(same as before), concatenate everything in one single df\n",
    "    train_dfs = {key: df for key, df in dfs.items() if key in train_keys}\n",
    "    \n",
    "    for key in train_keys:\n",
    "        print(key)\n",
    "    \n",
    "    train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "    #shuffle the training data\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    #generate test dictionary, i.e. take only rows not used in evaluation fro the defined scenario\n",
    "    test_dfs = {key: df.iloc[eval_size:] for key, df in dfs.items() if key in test_keys}\n",
    "    test_df = pd.concat(test_dfs, axis=0, ignore_index=True)\n",
    "    #shuffle the testing data\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    #split features and targets\n",
    "    if numpy_conversion:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1].to_numpy()\n",
    "        y_train=train_df.iloc[:,-1].to_numpy()\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1].to_numpy()\n",
    "        y_test=test_df.iloc[:,-1].to_numpy()\n",
    "    else:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1]\n",
    "        y_train=train_df.iloc[:,-1]\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1]\n",
    "        y_test=test_df.iloc[:,-1]\n",
    "\n",
    "\n",
    "    return train_ev_dfs_combined,X_train,y_train,X_test,y_test\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def train_test_my_split(dfs,test_track,numpy_conversion=True):\n",
    "    #take track three for testing and trcakk 1,2 for trainig\n",
    "    all_keys=list(dfs.keys())\n",
    "\n",
    "\n",
    "\n",
    "    if test_track==3:\n",
    "        train_indices=[0,1,3,4,6,7]\n",
    "        test_indices=[2,5,8]\n",
    "    elif test_track==2:\n",
    "        train_indices=[0,2,3,5,6,8]\n",
    "        test_indices=[1,4,7]\n",
    "    elif test_track==1:\n",
    "        train_indices=[1,2,4,5,7,8]\n",
    "        test_indices=[0,3,6]\n",
    "        \n",
    "\n",
    "    train_dfs = [dfs[all_keys[i]] for i in train_indices]\n",
    "    train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    # Shuffle the training data\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    test_dfs = [dfs[all_keys[i]] for i in test_indices]\n",
    "    test_df = pd.concat(test_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    \n",
    "    # Shuffle testing data\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    #split features and targets\n",
    "    if numpy_conversion:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1].to_numpy()\n",
    "        y_train=train_df.iloc[:,-1].to_numpy()\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1].to_numpy()\n",
    "        y_test=test_df.iloc[:,-1].to_numpy()\n",
    "    else:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1]\n",
    "        y_train=train_df.iloc[:,-1]\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1]\n",
    "        y_test=test_df.iloc[:,-1]\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "#function for creating the model based on the parameter type\n",
    "#--> returns the model\n",
    "def create_model(type):\n",
    "    if type==\"RandomForest\":\n",
    "        return RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif type == \"SVM\":\n",
    "        return SVC(kernel=\"rbf\", C=1.0)\n",
    "    elif type == \"lr\":\n",
    "        return LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "#test the model on the TEST set, take as input the NON-WINDOWED datasets\n",
    "#-->returns the accuracy on the test set\n",
    "\n",
    "def test_model(X_train,y_train,X_test,y_test,model_type,test_track=3):\n",
    "    #create the  model \n",
    "\n",
    "    #print(\"Test the model\")\n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "\n",
    "    model=create_model(model_type)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return test_accuracy\n",
    "    \n",
    "\n",
    "# function for cross-fold evaluation, with num_folds folds, taken as a parameter\n",
    "#--> returns average accuracy for the specific hyperparameters configuration defined as input\n",
    "\n",
    "def evaluate_model(X_train,y_train,model_type,num_folds,test_track=3):\n",
    "    \n",
    "    #create the  model \n",
    "    model=create_model(model_type)\n",
    "\n",
    "    #APPLY CROSS-FOLDER EVALUATION\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for i,(train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        X_ttrain, X_val = X_train[train_index], X_train[val_index] \n",
    "        y_ttrain, y_val = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "        model.fit(X_ttrain, y_ttrain) \n",
    "        y_pred = model.predict(X_val) \n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_pred) \n",
    "        #print((y_val != y_pred).sum())\n",
    "        print(f'fold {i} accuracy:', accuracy)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = sum(fold_accuracies) / num_folds\n",
    "    print('average of folds',average_accuracy)\n",
    "\n",
    "    return average_accuracy\n",
    "\n",
    "#intermediate function, used for: \n",
    "#windowing based on the window size\n",
    "#-->returns X_train,y_train,X_test,y_test based on track defined in test_track\n",
    "\n",
    "\n",
    "def window_and_split(dfs,window_size,test_track=3,numpy_conversion=True):\n",
    "    # Load the windowed data\n",
    "    with open(f\"dfs_windowed_{window_size}.pkl\", \"rb\") as file:\n",
    "        dfs_windowed = pickle.load(file)\n",
    "\n",
    "    return train_test_my_split(dfs_windowed,test_track,numpy_conversion)\n",
    "\n",
    "def window_and_split_LOCO(dfs,window_size,test_track=3,numpy_conversion=True):\n",
    "    # Load the windowed data\n",
    "    with open(f\"dfs_windowed_{window_size}.pkl\", \"rb\") as file:\n",
    "        dfs_windowed = pickle.load(file)\n",
    "    \n",
    "    train_ev_dfs,X_train,y_train,X_test,y_test=train_test_with_partial_ciruits_split(dfs_windowed,test_track,numpy_conversion)\n",
    "\n",
    "    return train_ev_dfs,X_train,y_train,X_test,y_test\n",
    "\n",
    "#receives X_train and X_test ALREADY SCALED  and returns pca datasets, as numpy arrays.\n",
    "def apply_PCA(X_train,X_test,threshold):\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train)\n",
    "    X_test_scaled = pd.DataFrame(X_test)\n",
    "\n",
    "    pca=PCA()\n",
    "\n",
    "    pca=PCA(n_components=threshold, random_state=29)\n",
    "    X_train_pca=pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca=pca.transform(X_test_scaled)\n",
    "\n",
    "    return X_train_pca,X_test_pca\n",
    "\n",
    "def save_results_to_csv(results, best_params, test_accuracy,model_type,pca_threshold):\n",
    "    # Convert the results to a DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy'])\n",
    "    \n",
    "    # Add the best parameters and test accuracy as new columns\n",
    "    test_accuracy_df = pd.DataFrame([test_accuracy], columns=[f'Test on {best_params}'])\n",
    "\n",
    "    # Combine the results, best parameters, and test accuracy into one DataFrame\n",
    "    final_df = pd.concat([results_df, test_accuracy_df], axis=1)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    final_df.to_csv(f'grid_search_results_with_test_accuracy_{model_type}_{pca_threshold}.csv', index=False, sep =\";\")\n",
    "\n",
    "    print(\"Results saved to 'grid_search_results_with_test_accuracy.csv'\")\n",
    "\n",
    "\n",
    "\n",
    "#main function, takes hyperparameters options, model type and num_folds for k-fold\n",
    "#tries all configurations on the evaluation set\n",
    "#test the best configuration on the trainig set \n",
    "\n",
    "def apply_grid_search(X_train,y_train,X_test,y_test,model_type,num_folds):\n",
    "\n",
    "\n",
    "    if model_type==\"lr\":\n",
    "        #define pipeline for lr\n",
    "        pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures()),  # Add polynomial features\n",
    "        ('scaler', StandardScaler()),    # Standardize features\n",
    "        ('logreg', LogisticRegression()) # Logistic Regression model\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'poly__degree': [3],                   # Degrees of polynomial features\n",
    "            'logreg__C': [0.1, 1, 10, 100],           # Regularization strength (inverse of lambda)\n",
    "            #'logreg__solver': ['lbfgs'],                    # Use solver suitable for small datasets\n",
    "            'logreg__max_iter': [100, 200, 500],            # Maximum iterations\n",
    "        }\n",
    "    if model_type==\"RandomForest\":\n",
    "        pipeline = Pipeline([\n",
    "        #('scaler', StandardScaler()),   # Feature scaling (optional for Random Forest)\n",
    "        ('rf', RandomForestClassifier(random_state=42))  # Random Forest Classifier\n",
    "        ])\n",
    "\n",
    "    # Define the hyperparameters to search over\n",
    "        param_grid = {\n",
    "            'rf__n_estimators': [50, 200],              # Number of trees in the forest\n",
    "            'rf__max_depth': [None, 30],              # Maximum depth of the trees\n",
    "            'rf__min_samples_split': [2, 10],              # Minimum number of samples required to split an internal node\n",
    "            #'rf__min_samples_leaf': [1, 2, 4],                # Minimum number of samples required to be at a leaf node\n",
    "            'rf__bootstrap': [True, False],                   # Whether bootstrap samples are used when building trees\n",
    "            'rf__max_features': [ 'sqrt', 'log2']     # The number of features to consider when looking for the best split\n",
    "        }\n",
    "\n",
    "    # Create a manual loop with tqdm\n",
    "    results = []\n",
    "    param_combinations = list(ParameterGrid(param_grid))\n",
    "\n",
    "    for params in tqdm(param_combinations, desc=\"Grid Search Progress\"):\n",
    "        pipeline.set_params(**params)  # Set the current parameters\n",
    "        # Perform cross-validation and get the mean accuracy score\n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        # Append the results with the mean score\n",
    "        results.append((params, np.mean(scores)))\n",
    "\n",
    "    # Sort results by accuracy\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "    best_params = results[0][0]\n",
    "\n",
    "    # Display best result\n",
    "    print(\"\\nBest Parameters:\", results[0][0])\n",
    "    print(\"Best Score:\", results[0][1])\n",
    "\n",
    "    pipeline.set_params(**best_params)\n",
    "    pipeline.fit(X_train, y_train)  # Fit on the entire training data\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    return results,best_params,test_accuracy\n",
    "\n",
    "\n",
    "def LOCO_cross_validation(dfs,model_type,PCA_thresholds,window_size,test_track=3):\n",
    "    # Load the windowed data\n",
    "    train_ev_dfs, X_train, y_train, X_test, y_test = window_and_split_LOCO(dfs, window_size, test_track, numpy_conversion=True)\n",
    "    print(\"done with windowing\")\n",
    "    \n",
    "    # Define param_grid based on model type\n",
    "    if model_type == \"lr\":\n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        pipeline = Pipeline([\n",
    "            ('poly', PolynomialFeatures()),  # Add polynomial features\n",
    "            ('scaler', StandardScaler()),    # Standardize features\n",
    "            ('pca', PCA()), #apply PCA\n",
    "            ('logreg', LogisticRegression()) # Logistic Regression model\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'poly__degree': [1,2],                   # Degrees of polynomial features\n",
    "            'logreg__C': [0.1, 1, 10, 100],        # Regularization strength (inverse of lambda)\n",
    "            'logreg__max_iter': [100, 200, 500],   # Maximum iterations\n",
    "            'pca__n_components': PCA_thresholds\n",
    "        }\n",
    "\n",
    "    elif model_type == \"RandomForest\":\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),    # Standardize features\n",
    "            ('pca', PCA()), #apply PCA\n",
    "            ('rf', RandomForestClassifier(random_state=42))  # Random Forest Classifier\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'rf__n_estimators': [50, 200],            # Number of trees in the forest\n",
    "            'rf__max_depth': [None, 30],              # Maximum depth of the trees\n",
    "            'rf__min_samples_split': [2, 10],         # Minimum number of samples required to split an internal node\n",
    "            'rf__bootstrap': [True, False],           # Whether bootstrap samples are used when building trees\n",
    "            'rf__max_features': ['sqrt', 'log2'],     # The number of features to consider when looking for the best split\n",
    "            'pca__n_components': PCA_thresholds\n",
    "        }\n",
    "\n",
    "    # Generate all combinations of hyperparameters\n",
    "    hyperpar_keys = param_grid.keys()\n",
    "    combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    best_combination = (None, 0)\n",
    "\n",
    "    for combination in combinations:\n",
    "        param_dict = dict(zip(hyperpar_keys, combination))\n",
    "        print(f\"Combination: {param_dict}\")\n",
    "\n",
    "        # Evaluate the model\n",
    "        model = pipeline\n",
    "        model.set_params(**param_dict)\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        # Apply Cross-Folder Evaluation\n",
    "        for eval_key in train_ev_dfs.keys():\n",
    "            eval = train_ev_dfs[eval_key]\n",
    "            eval = eval.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "            X_eval = eval.iloc[:, :-1].to_numpy()\n",
    "            y_eval = eval.iloc[:, -1].to_numpy()\n",
    "\n",
    "            # Use remaining keys as the training set\n",
    "            train_keys = [key for key in train_ev_dfs.keys() if key != eval_key]\n",
    "            train_combined=pd.concat([train_ev_dfs[key] for key in train_keys], axis=0, ignore_index=True)\n",
    "            \n",
    "            train_combined = train_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "            X_train_combined = train_combined.iloc[:, :-1].to_numpy()\n",
    "            y_train_combined = train_combined.iloc[:, -1].to_numpy()\n",
    "\n",
    "            # Train the model on the training set\n",
    "            model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "            # Evaluate the model on the evaluation set\n",
    "            y_eval_pred = model.predict(X_eval)\n",
    "            eval_accuracy = accuracy_score(y_eval, y_eval_pred)\n",
    "\n",
    "            # Append the results\n",
    "            results.append((eval_key, eval_accuracy))\n",
    "\n",
    "        # Compute the average accuracy\n",
    "        average_accuracy = np.mean([acc for key, acc in results])\n",
    "        if average_accuracy > best_combination[1] or best_combination[0] is None:\n",
    "            best_combination = (combination, average_accuracy)\n",
    "        print(f\"Average Accuracy: {average_accuracy}\")\n",
    "\n",
    "    # Find the best hyperparameters from argmax of the average accuracy\n",
    "    print(f\"Best hyperparameters combination: {best_combination}\")\n",
    "\n",
    "    # Test the best hyperparameters on the test set\n",
    "    model = pipeline\n",
    "    model.set_params(**dict(zip(hyperpar_keys, best_combination[0])))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return best_combination, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84560ad9-9859-49e8-a33f-d368d43367b9",
   "metadata": {},
   "source": [
    "## IMPORT THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a2a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets_reduced, which is the temporal data truncated\n",
    "with open(\"datasets_reduced.pkl\", \"rb\") as file:\n",
    "    datasets_reduced = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a558e1-b198-415b-ad0b-15e509d9b77b",
   "metadata": {},
   "source": [
    "## TEST THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efa0d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvs1_gps_mpu\n",
      "pvs4_gps_mpu\n",
      "pvs7_gps_mpu\n",
      "pvs2_gps_mpu\n",
      "pvs5_gps_mpu\n",
      "pvs8_gps_mpu\n",
      "done with windowing\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.40788279528069493\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.40788279528069493\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42110722157396613\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42110722157396613\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42084791909762737\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42084791909762737\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41475431090366915\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41475431090366915\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.40788279528069493\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.40788279528069493\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42110722157396613\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42110722157396613\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42084791909762737\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.42084791909762737\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41475431090366915\n",
      "Combination: {'rf__n_estimators': 50, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41475431090366915\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41553221833268505\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41553221833268505\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.411513029949436\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': None, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.411513029949436\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41553221833268505\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 2, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.41553221833268505\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': True, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.4135874497601452\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'sqrt', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.411513029949436\n",
      "Combination: {'rf__n_estimators': 200, 'rf__max_depth': 30, 'rf__min_samples_split': 10, 'rf__bootstrap': False, 'rf__max_features': 'log2', 'pca__n_components': 0.6}\n",
      "Average Accuracy: 0.411513029949436\n",
      "Best hyperparameters combination: ((50, None, 2, False, 'sqrt', 0.6), 0.42110722157396613)\n",
      "Test set accuracy: 0.4743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(((50, None, 2, False, 'sqrt', 0.6), 0.42110722157396613), 0.47433903576982894)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type=\"RandomForest\"\n",
    "window_sizes=50\n",
    "num_folds = 5\n",
    "test_track=3\n",
    "thresholds_pca=[0.6]\n",
    "LOCO_cross_validation(datasets_reduced,model_type,thresholds_pca,window_sizes,test_track=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4a795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
