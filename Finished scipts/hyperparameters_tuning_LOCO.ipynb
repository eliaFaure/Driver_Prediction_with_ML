{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec03935-e373-428f-a845-66a34c0219ad",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL AND EVALUATE IT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ec4a13-9fbc-4f6e-9c9d-ea61b2bcbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for code tt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score, KFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d65b83-5b4f-411f-9203-2c3ae02508f3",
   "metadata": {},
   "source": [
    "## DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a14fc20-06cd-4fdb-a8f9-ce3bed23426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "#define train_test splits, based on the track we define in test_track. \n",
    "#we use test_track for testing and the other two tracks for training\n",
    "#-->returns X_train,y_train,X_test,y_test as numpy arrays\n",
    "\n",
    "def train_test_with_partial_ciruits_split(dfs,test_track,numpy_conversion=True):\n",
    "    #generate train and test dictionary\n",
    "\n",
    "    keys=list(dfs.keys())\n",
    "\n",
    "    scenario1_indices=[0,3,6]\n",
    "    scenario2_indices=[1,4,7]\n",
    "    scenario3_indices=[2,5,8]\n",
    "\n",
    "    scenario1_keys=[keys[i] for i in scenario1_indices]\n",
    "    scenario2_keys=[keys[i] for i in scenario2_indices]\n",
    "    scenario3_keys=[keys[i] for i in scenario3_indices]\n",
    "\n",
    "    #generate train dictionary(same as before)\n",
    "\n",
    "    if test_track==3:\n",
    "        train_keys=scenario1_keys+scenario2_keys\n",
    "        test_keys=scenario3_keys\n",
    "    elif test_track==2:\n",
    "        train_keys=scenario1_keys+scenario3_keys\n",
    "        test_keys=scenario2_keys\n",
    "    elif test_track==1:\n",
    "        train_keys=scenario2_keys+scenario3_keys\n",
    "        test_keys=scenario1_keys\n",
    "    \n",
    "    #take the minimum length of the dataframes\n",
    "    min_length = min([len(df) for df in dfs.values()])\n",
    "    eval_size = int(0.4 * min_length)\n",
    "\n",
    "    #take the first eval_size rows for evaluation, consider all dfs\n",
    "    train_ev_dfs = {key: df.iloc[:eval_size] for key, df in dfs.items()}\n",
    "\n",
    "    #concatenate different drivers in the same circuit in the same dataframe\n",
    "\n",
    "    train_ev_dfs_combined = {\n",
    "        \"scenario1\": pd.concat([train_ev_dfs[key] for key in scenario1_keys], axis=0, ignore_index=True),\n",
    "        \"scenario2\": pd.concat([train_ev_dfs[key] for key in scenario2_keys], axis=0, ignore_index=True),\n",
    "        \"scenario3\": pd.concat([train_ev_dfs[key] for key in scenario3_keys], axis=0, ignore_index=True)\n",
    "    }\n",
    "\n",
    "\n",
    "    #shuffle the dataframes\n",
    "    for key, df in train_ev_dfs_combined.items():\n",
    "        train_ev_dfs_combined[key] = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "    #generate train dictionary(same as before), concatenate everything in one single df\n",
    "    train_dfs = {key: df for key, df in dfs.items() if key in train_keys}\n",
    "    \n",
    "    for key in train_keys:\n",
    "        print(key)\n",
    "    \n",
    "    train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "    #shuffle the training data\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    #generate test dictionary, i.e. take only rows not used in evaluation fro the defined scenario\n",
    "    test_dfs = {key: df.iloc[eval_size:] for key, df in dfs.items() if key in test_keys}\n",
    "    test_df = pd.concat(test_dfs, axis=0, ignore_index=True)\n",
    "    #shuffle the testing data\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    #SVM and XGBoost expects targets from going from 0, so convert to int and set labels as 0, 1, 2\n",
    "    train_df.iloc[:, -1] = train_df.iloc[:, -1].astype(int) - 1\n",
    "    test_df.iloc[:, -1] = test_df.iloc[:, -1].astype(int) - 1\n",
    "\n",
    "    #split features and targets\n",
    "    if numpy_conversion:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1].to_numpy()\n",
    "        y_train=train_df.iloc[:,-1].to_numpy()\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1].to_numpy()\n",
    "        y_test=test_df.iloc[:,-1].to_numpy()\n",
    "    else:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1]\n",
    "        y_train=train_df.iloc[:,-1]\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1]\n",
    "        y_test=test_df.iloc[:,-1]\n",
    "\n",
    "    return train_ev_dfs_combined,X_train,y_train,X_test,y_test\n",
    "\n",
    "\n",
    "\n",
    "#function for creating the model based on the parameter type\n",
    "#--> returns the model\n",
    "def create_model(type):\n",
    "    if type==\"RandomForest\":\n",
    "        return RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif type == \"SVM\":\n",
    "        return SVC(kernel=\"rbf\", C=1.0, random_state=42)\n",
    "    elif type == \"lr\":\n",
    "        return LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif type == \"XGBoost\":  # Adding XGBoost\n",
    "        return XGBClassifier(\n",
    "            n_estimators=100,        # Number of trees\n",
    "            max_depth=3,             # Maximum depth of trees\n",
    "            learning_rate=0.1,       # Learning rate (eta)\n",
    "            subsample=0.8,           # Subsample ratio of the training set\n",
    "            colsample_bytree=0.8,    # Subsample ratio of columns\n",
    "            random_state=42          # Seed for reproducibility\n",
    "        )\n",
    "\n",
    "#test the model on the TEST set, take as input the NON-WINDOWED datasets\n",
    "#-->returns the accuracy on the test set\n",
    "\n",
    "'''\n",
    "def test_model(X_train,y_train,X_test,y_test,model_type,test_track=3):\n",
    "    #create the  model \n",
    "\n",
    "    #print(\"Test the model\")\n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "\n",
    "    model=create_model(model_type)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return test_accuracy\n",
    "'''    \n",
    "\n",
    "# function for cross-fold evaluation, with num_folds folds, taken as a parameter\n",
    "#--> returns average accuracy for the specific hyperparameters configuration defined as input\n",
    "\n",
    "'''\n",
    "def evaluate_model(X_train,y_train,model_type,num_folds,test_track=3):\n",
    "    \n",
    "    #create the  model \n",
    "    model=create_model(model_type)\n",
    "\n",
    "    #APPLY CROSS-FOLDER EVALUATION\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for i,(train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        X_ttrain, X_val = X_train[train_index], X_train[val_index] \n",
    "        y_ttrain, y_val = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "        model.fit(X_ttrain, y_ttrain) \n",
    "        y_pred = model.predict(X_val) \n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_pred) \n",
    "        #print((y_val != y_pred).sum())\n",
    "        print(f'fold {i} accuracy:', accuracy)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = sum(fold_accuracies) / num_folds\n",
    "    print('average of folds',average_accuracy)\n",
    "\n",
    "    return average_accuracy\n",
    "'''\n",
    "    \n",
    "#intermediate function, used for: \n",
    "#windowing based on the window size\n",
    "#-->returns X_train,y_train,X_test,y_test based on track defined in test_track\n",
    "\n",
    "def window_and_split_LOCO(dfs,window_size,ratio,test_track=3,numpy_conversion=True):\n",
    "    # Load the windowed data\n",
    "    print(ratio)\n",
    "    directory = 'datasets'\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    file_path = os.path.join(directory, f'dfs_windowed_{ratio}.pkl')\n",
    "    #file_path = os.path.join(directory, f'dfs_windowed_{window_size}_rd{ratio}.pkl')\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        dfs_windowed = pickle.load(file)\n",
    "    for i in dfs_windowed.keys():\n",
    "        print(len(dfs_windowed[i]))\n",
    "    train_ev_dfs,X_train,y_train,X_test,y_test=train_test_with_partial_ciruits_split(dfs_windowed,test_track,numpy_conversion)\n",
    "\n",
    "    return train_ev_dfs,X_train,y_train,X_test,y_test\n",
    "\n",
    "#receives X_train and X_test ALREADY SCALED  and returns pca datasets, as numpy arrays.\n",
    "'''\n",
    "def apply_PCA(X_train,X_test,threshold):\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train)\n",
    "    X_test_scaled = pd.DataFrame(X_test)\n",
    "\n",
    "    pca=PCA()\n",
    "\n",
    "    pca=PCA(n_components=threshold, random_state=29)\n",
    "    X_train_pca=pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca=pca.transform(X_test_scaled)\n",
    "\n",
    "    return X_train_pca,X_test_pca\n",
    "'''\n",
    "\n",
    "'''    \n",
    "def save_results_to_csv(results, best_params, test_accuracy,model_type,pca_threshold,window_size,reduction_factor=2):\n",
    "    # Convert the results to a DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy'])\n",
    "    \n",
    "    # Add the best parameters and test accuracy as new columns\n",
    "    test_accuracy_df = pd.DataFrame([test_accuracy], columns=[f'Test on {best_params}'])\n",
    "\n",
    "    # Combine the results, best parameters, and test accuracy into one DataFrame\n",
    "    final_df = pd.concat([results_df, test_accuracy_df], axis=1)\n",
    "    # Ensure the 'results' directory exists\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    # Define the file path within the 'results' directory\n",
    "    file_path = os.path.join('results', f'grid_search_results_{model_type}_{pca_threshold}_red{reduction_factor}_ws{window_size}.csv')\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    final_df.to_csv(file_path, index=False, sep =\";\")\n",
    "\n",
    "    print(f\"Results saved to 'grid_search_results_{model_type}_{pca_threshold}.csv'\")\n",
    "'''\n",
    "\n",
    "\n",
    "def LOCO_cross_validation(dfs,model_type,PCA_thresholds,window_size,ratio,test_track=3):\n",
    "    # Load the windowed data\n",
    "    train_ev_dfs, X_train, y_train, X_test, y_test = window_and_split_LOCO(dfs, window_size, ratio, test_track, numpy_conversion=True)\n",
    "    print(\"done with windowing\")\n",
    "    \n",
    "    # Define param_grid based on model type\n",
    "    if model_type == \"lr\":\n",
    "        \n",
    "        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "        pipeline = Pipeline([\n",
    "            ('poly', PolynomialFeatures()),  # Add polynomial features\n",
    "            ('scaler', StandardScaler()),    # Standardize features\n",
    "            ('pca', PCA()), #apply PCA\n",
    "            ('logreg', LogisticRegression()) # Logistic Regression model\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'poly__degree': [1,2],                   # Degrees of polynomial features\n",
    "            'logreg__C': [0.1, 1, 10, 100],        # Regularization strength (inverse of lambda)\n",
    "            'logreg__max_iter': [100, 200, 500],   # Maximum iterations\n",
    "            'pca__n_components': PCA_thresholds\n",
    "        }\n",
    "\n",
    "    elif model_type == \"RandomForest\":\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),    # Standardize features\n",
    "            ('pca', PCA()), #apply PCA\n",
    "            ('rf', RandomForestClassifier(random_state=42))  # Random Forest Classifier\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'rf__n_estimators': [100,   200],            # Number of trees in the forest\n",
    "            'rf__max_depth': [None, 30],              # Maximum depth of the trees\n",
    "            'rf__min_samples_split': [2, 10],         # Minimum number of samples required to split an internal node\n",
    "            'rf__bootstrap': [True, False],           # Whether bootstrap samples are used when building trees\n",
    "            'rf__max_features': [ 'sqrt'],     # The number of features to consider when looking for the best split\n",
    "            'pca__n_components': PCA_thresholds\n",
    "        }\n",
    "    \n",
    "    elif model_type == \"svm\":\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),    # Standardize features\n",
    "            ('pca', PCA()),                  # Apply PCA\n",
    "            ('svm', SVC(random_state=42))   # Support Vector Machine model\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'svm__C': [0.1],#, 1, 10],#, 100],            # Regularization parameter, controls tradeoff between slack variable penalty and the margin\n",
    "            'svm__kernel': ['rbf'],#, 'linear'],       # Kernel type\n",
    "            'svm__gamma': [0.1], #['scale', 'auto', 0.1],#, 0.1],  # Kernel coefficient for RBF\n",
    "            'pca__n_components': PCA_thresholds    # Number of PCA components\n",
    "        }\n",
    "    \n",
    "    elif model_type == \"xgboost\":\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),    # Standardize features\n",
    "            ('pca', PCA()),                  # Apply PCA\n",
    "            ('xgb', XGBClassifier(random_state=42))  # XGBoost Classifier\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'xgb__n_estimators': [100, 200],       # Number of boosting rounds (trees)\n",
    "            'xgb__max_depth': [3, 6, 9],          # Maximum depth of the trees\n",
    "            'xgb__learning_rate': [0.01, 0.1, 0.2],  # Learning rate (eta)\n",
    "            'xgb__subsample': [0.8, 1.0],         # Fraction of samples used for each tree\n",
    "            'xgb__colsample_bytree': [0.8, 1.0],  # Fraction of features (columns) used for each tree\n",
    "            'pca__n_components': PCA_thresholds   # Number of PCA components\n",
    "        }\n",
    "\n",
    "\n",
    "    # Generate all combinations of hyperparameters\n",
    "    hyperpar_keys = param_grid.keys()\n",
    "    combinations = list(itertools.product(*param_grid.values()))\n",
    "    combinations_results = []\n",
    "\n",
    "    best_combination = (None, 0)\n",
    "\n",
    "    for combination in combinations:\n",
    "        param_dict = dict(zip(hyperpar_keys, combination))\n",
    "        print(f\"Combination: {param_dict}\")\n",
    "\n",
    "        # Evaluate the model\n",
    "        model = pipeline\n",
    "        model.set_params(**param_dict)\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        # Apply Cross-Folder Evaluation\n",
    "        for eval_key in train_ev_dfs.keys():\n",
    "            eval = train_ev_dfs[eval_key]\n",
    "            eval = eval.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "            X_eval = eval.iloc[:, :-1].to_numpy()\n",
    "            y_eval = eval.iloc[:, -1].to_numpy()\n",
    "\n",
    "            # Use remaining keys as the training set\n",
    "            train_keys = [key for key in train_ev_dfs.keys() if key != eval_key]\n",
    "            train_combined=pd.concat([train_ev_dfs[key] for key in train_keys], axis=0, ignore_index=True)\n",
    "            \n",
    "            train_combined = train_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "            X_train_combined = train_combined.iloc[:, :-1].to_numpy()\n",
    "            y_train_combined = train_combined.iloc[:, -1].to_numpy()\n",
    "\n",
    "            y_train_combined = LabelEncoder().fit_transform(y_train_combined)\n",
    "            y_eval = LabelEncoder().fit_transform(y_eval)\n",
    "\n",
    "            # Train the model on the training set\n",
    "            model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "            # Evaluate the model on the evaluation set\n",
    "            y_eval_pred = model.predict(X_eval)\n",
    "            eval_accuracy = accuracy_score(y_eval, y_eval_pred)\n",
    "\n",
    "            # Append the results\n",
    "            results.append((eval_key, eval_accuracy))\n",
    "\n",
    "        # Compute the average accuracy\n",
    "        average_accuracy = np.mean([acc for key, acc in results])\n",
    "        combinations_results.append((param_dict, average_accuracy))\n",
    "\n",
    "        if average_accuracy > best_combination[1] or best_combination[0] is None:\n",
    "            best_combination = (combination, average_accuracy)\n",
    "        print(f\"Average Accuracy: {average_accuracy}\")\n",
    "\n",
    "    # Find the best hyperparameters from argmax of the average accuracy\n",
    "    print(f\"Best hyperparameters combination: {best_combination}\")\n",
    "\n",
    "    # Test the best hyperparameters on the test set\n",
    "    model = pipeline\n",
    "    model.set_params(**dict(zip(hyperpar_keys, best_combination[0])))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    #save_results_to_csv(combinations_results, best_combination[0], test_accuracy, model_type, PCA_thresholds,window_size,ratio)\n",
    "\n",
    "    return best_combination, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84560ad9-9859-49e8-a33f-d368d43367b9",
   "metadata": {},
   "source": [
    "## IMPORT THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4a2a841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile_path = \\'datasets_reduced.pkl\\'\\nwith open(file_path, \"rb\") as file:\\n    datasets_reduced = pickle.load(file)\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets_reduced, which is the temporal data truncated\n",
    "\n",
    "\n",
    "directory = 'datasets'\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "file_path = os.path.join(directory, 'datasets_reduced.pkl')\n",
    "with open(file_path, \"rb\") as file:\n",
    "    datasets_reduced = pickle.load(file)\n",
    "\n",
    "'''\n",
    "file_path = 'datasets_reduced.pkl'\n",
    "with open(file_path, \"rb\") as file:\n",
    "    datasets_reduced = pickle.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a558e1-b198-415b-ad0b-15e509d9b77b",
   "metadata": {},
   "source": [
    "## TEST THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efa0d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "4729\n",
      "4729\n",
      "4729\n",
      "4495\n",
      "4495\n",
      "4495\n",
      "4285\n",
      "4285\n",
      "4285\n",
      "pvs1_gps_mpu\n",
      "pvs4_gps_mpu\n",
      "pvs7_gps_mpu\n",
      "pvs2_gps_mpu\n",
      "pvs5_gps_mpu\n",
      "pvs8_gps_mpu\n",
      "done with windowing\n",
      "Combination: {'svm__C': 0.1, 'svm__kernel': 'rbf', 'svm__gamma': 0.1, 'pca__n_components': 0.8}\n",
      "Average Accuracy: 0.5047970958122651\n",
      "Best hyperparameters combination: ((0.1, 'rbf', 0.1, 0.8), 0.5047970958122651)\n",
      "Test set accuracy: 0.4230\n"
     ]
    }
   ],
   "source": [
    "model_type=\"svm\"\n",
    "window_sizes=[20]\n",
    "test_track=3\n",
    "thresholds_pca=[0.8]\n",
    "ratio=100\n",
    "for window_size in window_sizes:\n",
    "    LOCO_cross_validation(datasets_reduced,model_type,thresholds_pca,window_size,ratio,test_track=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4a795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
