{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec03935-e373-428f-a845-66a34c0219ad",
   "metadata": {},
   "source": [
    "## TRAIN THE MODEL AND EVALUATE IT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ec4a13-9fbc-4f6e-9c9d-ea61b2bcbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for code\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit, KFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d65b83-5b4f-411f-9203-2c3ae02508f3",
   "metadata": {},
   "source": [
    "## DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a14fc20-06cd-4fdb-a8f9-ce3bed23426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train_test splits, based on the track we define in test_track. \n",
    "#we use test_track for testing and the other two tracks for training\n",
    "#-->returns X_train,y_train,X_test,y_test as numpy arrays\n",
    "\n",
    "\n",
    "def train_test_my_split(dfs,test_track,numpy_conversion=True):\n",
    "    #take track three for testing and trcakk 1,2 for trainig\n",
    "    all_keys=list(dfs.keys())\n",
    "\n",
    "\n",
    "\n",
    "    if test_track==3:\n",
    "        train_indices=[0,1,3,4,6,7]\n",
    "        test_indices=[2,5,8]\n",
    "    elif test_track==2:\n",
    "        train_indices=[0,2,3,5,6,8]\n",
    "        test_indices=[1,4,7]\n",
    "    elif test_track==1:\n",
    "        train_indices=[1,2,4,5,7,8]\n",
    "        test_indices=[0,3,6]\n",
    "        \n",
    "\n",
    "    train_dfs = [dfs[all_keys[i]] for i in train_indices]\n",
    "    train_df = pd.concat(train_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    # Shuffle the training data\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    test_dfs = [dfs[all_keys[i]] for i in test_indices]\n",
    "    test_df = pd.concat(test_dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    \n",
    "    # Shuffle testing data\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    #split features and targets\n",
    "    if numpy_conversion:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1].to_numpy()\n",
    "        y_train=train_df.iloc[:,-1].to_numpy()\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1].to_numpy()\n",
    "        y_test=test_df.iloc[:,-1].to_numpy()\n",
    "    else:\n",
    "        #split features and targets\n",
    "        X_train=train_df.iloc[:,:-1]\n",
    "        y_train=train_df.iloc[:,-1]\n",
    "    \n",
    "        X_test=test_df.iloc[:,:-1]\n",
    "        y_test=test_df.iloc[:,-1]\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "#function for creating the model based on the parameter type\n",
    "#--> returns the model\n",
    "def create_model(type):\n",
    "    if type==\"RandomForest\":\n",
    "        return RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    elif type == \"SVM\":\n",
    "        return SVC(kernel=\"rbf\", C=1.0)\n",
    "    elif type == \"lr\":\n",
    "        return LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "#test the model on the TEST set, take as input the NON-WINDOWED datasets\n",
    "#-->returns the accuracy on the test set\n",
    "\n",
    "def test_model(X_train,y_train,X_test,y_test,model_type,test_track=3):\n",
    "    #create the  model \n",
    "\n",
    "    #print(\"Test the model\")\n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "\n",
    "    model=create_model(model_type)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"Test set accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return test_accuracy\n",
    "    \n",
    "\n",
    "# function for cross-fold evaluation, with num_folds folds, taken as a parameter\n",
    "#--> returns average accuracy for the specific hyperparameters configuration defined as input\n",
    "\n",
    "def evaluate_model(X_train,y_train,model_type,num_folds,test_track=3):\n",
    "    \n",
    "    #create the  model \n",
    "    model=create_model(model_type)\n",
    "\n",
    "    #APPLY CROSS-FOLDER EVALUATION\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for i,(train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        X_ttrain, X_val = X_train[train_index], X_train[val_index] \n",
    "        y_ttrain, y_val = y_train[train_index], y_train[val_index]\n",
    "            \n",
    "        model.fit(X_ttrain, y_ttrain) \n",
    "        y_pred = model.predict(X_val) \n",
    "        \n",
    "        accuracy = accuracy_score(y_val, y_pred) \n",
    "        #print((y_val != y_pred).sum())\n",
    "        print(f'fold {i} accuracy:', accuracy)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = sum(fold_accuracies) / num_folds\n",
    "    print('average of folds',average_accuracy)\n",
    "\n",
    "    return average_accuracy\n",
    "\n",
    "#intermediate function, used for: \n",
    "#windowing based on the window size\n",
    "#-->returns X_train,y_train,X_test,y_test based on track defined in test_track\n",
    "\n",
    "\n",
    "def window_and_split(dfs,window_size,test_track=3,numpy_conversion=True):\n",
    "    # Load the windowed data\n",
    "    with open(f\"dfs_windowed_{window_size}.pkl\", \"rb\") as file:\n",
    "        dfs_windowed = pickle.load(file)\n",
    "\n",
    "    return train_test_my_split(dfs_windowed,test_track,numpy_conversion)\n",
    "\n",
    "\n",
    "#receives X_train and X_test ALREADY SCALED  and returns pca datasets, as numpy arrays.\n",
    "def apply_PCA(X_train,X_test,threshold):\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train)\n",
    "    X_test_scaled = pd.DataFrame(X_test)\n",
    "\n",
    "    pca=PCA()\n",
    "\n",
    "    pca=PCA(n_components=threshold, random_state=29)\n",
    "    X_train_pca=pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca=pca.transform(X_test_scaled)\n",
    "\n",
    "    return X_train_pca,X_test_pca\n",
    "\n",
    "def save_results_to_csv(results, best_params, test_accuracy,model_type,pca_threshold):\n",
    "    # Convert the results to a DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=['Parameters', 'Mean Accuracy'])\n",
    "    \n",
    "    # Add the best parameters and test accuracy as new columns\n",
    "    test_accuracy_df = pd.DataFrame([test_accuracy], columns=[f'Test on {best_params}'])\n",
    "\n",
    "    # Combine the results, best parameters, and test accuracy into one DataFrame\n",
    "    final_df = pd.concat([results_df, test_accuracy_df], axis=1)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    final_df.to_csv(f'grid_search_results_with_test_accuracy_{model_type}_{pca_threshold}.csv', index=False, sep =\";\")\n",
    "\n",
    "    print(\"Results saved to 'grid_search_results_with_test_accuracy.csv'\")\n",
    "\n",
    "\n",
    "\n",
    "#main function, takes hyperparameters options, model type and num_folds for k-fold\n",
    "#tries all configurations on the evaluation set\n",
    "#test the best configuration on the trainig set \n",
    "\n",
    "def apply_grid_search(X_train,y_train,X_test,y_test,model_type,num_folds):\n",
    "\n",
    "\n",
    "    if model_type==\"lr\":\n",
    "        #define pipeline for lr\n",
    "        pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures()),  # Add polynomial features\n",
    "        ('scaler', StandardScaler()),    # Standardize features\n",
    "        ('logreg', LogisticRegression()) # Logistic Regression model\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            'poly__degree': [3],                   # Degrees of polynomial features\n",
    "            'logreg__C': [0.1, 1, 10, 100],           # Regularization strength (inverse of lambda)\n",
    "            #'logreg__solver': ['lbfgs'],                    # Use solver suitable for small datasets\n",
    "            'logreg__max_iter': [100, 200, 500],            # Maximum iterations\n",
    "        }\n",
    "    if model_type==\"RandomForest\":\n",
    "        pipeline = Pipeline([\n",
    "        #('scaler', StandardScaler()),   # Feature scaling (optional for Random Forest)\n",
    "        ('rf', RandomForestClassifier(random_state=42))  # Random Forest Classifier\n",
    "        ])\n",
    "\n",
    "    # Define the hyperparameters to search over\n",
    "        param_grid = {\n",
    "            'rf__n_estimators': [50, 200],              # Number of trees in the forest\n",
    "            'rf__max_depth': [None, 30],              # Maximum depth of the trees\n",
    "            'rf__min_samples_split': [2, 10],              # Minimum number of samples required to split an internal node\n",
    "            #'rf__min_samples_leaf': [1, 2, 4],                # Minimum number of samples required to be at a leaf node\n",
    "            'rf__bootstrap': [True, False],                   # Whether bootstrap samples are used when building trees\n",
    "            'rf__max_features': [ 'sqrt', 'log2']     # The number of features to consider when looking for the best split\n",
    "        }\n",
    "\n",
    "    # Create a manual loop with tqdm\n",
    "    results = []\n",
    "    param_combinations = list(ParameterGrid(param_grid))\n",
    "\n",
    "    for params in tqdm(param_combinations, desc=\"Grid Search Progress\"):\n",
    "        pipeline.set_params(**params)  # Set the current parameters\n",
    "        # Perform cross-validation and get the mean accuracy score\n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        # Append the results with the mean score\n",
    "        results.append((params, np.mean(scores)))\n",
    "\n",
    "    # Sort results by accuracy\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "    best_params = results[0][0]\n",
    "\n",
    "    # Display best result\n",
    "    print(\"\\nBest Parameters:\", results[0][0])\n",
    "    print(\"Best Score:\", results[0][1])\n",
    "\n",
    "    pipeline.set_params(**best_params)\n",
    "    pipeline.fit(X_train, y_train)  # Fit on the entire training data\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    return results,best_params,test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84560ad9-9859-49e8-a33f-d368d43367b9",
   "metadata": {},
   "source": [
    "## IMPORT THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a2a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets_reduced, which is the temporal data truncated\n",
    "with open(\"datasets_reduced.pkl\", \"rb\") as file:\n",
    "    datasets_reduced = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a558e1-b198-415b-ad0b-15e509d9b77b",
   "metadata": {},
   "source": [
    "## TEST THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada19aa6-4362-4986-8227-f6e3f36b6d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "PCA threshold: 0.6\n",
      "Window size: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress: 100%|██████████| 32/32 [6:02:26<00:00, 679.57s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'rf__bootstrap': False, 'rf__max_depth': None, 'rf__max_features': 'sqrt', 'rf__min_samples_split': 2, 'rf__n_estimators': 200}\n",
      "Best Score: 0.9968845500848896\n",
      "Test Accuracy: 0.6509918319719953\n",
      "Time taken for PCA threshold 0.6: 22405.91 seconds\n",
      "Results saved to 'grid_search_results_with_test_accuracy.csv'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import io\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import time\n",
    "\n",
    "model_type=\"RandomForest\"\n",
    "window_sizes=[1000]\n",
    "num_folds = 5\n",
    "test_track=3\n",
    "thresholds_pca=[0.6]\n",
    "\n",
    "for window_size in window_sizes:\n",
    "    for threshold_pca in thresholds_pca:\n",
    "        print(f\"----------------------\")\n",
    "        print(f\"PCA threshold: {threshold_pca}\")\n",
    "        print(f\"Window size: {window_size}\")\n",
    "\n",
    "        X_train,y_train,X_test,y_test=window_and_split(datasets_reduced,window_size,test_track,True)\n",
    "\n",
    "        #scale values\n",
    "        scaler=StandardScaler()\n",
    "        X_train_scaled=scaler.fit_transform(X_train)\n",
    "        X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "        #apply PCA\n",
    "        X_train_pca,X_test_pca=apply_PCA(X_train_scaled,X_test_scaled,threshold_pca)\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        final_results,best_params,test_accuracy=apply_grid_search(X_train_pca,y_train,X_test_pca,y_test,model_type,num_folds)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Time taken for PCA threshold {threshold_pca}: {elapsed_time:.2f} seconds\")\n",
    "        # Call the function to save results to a CSV file\n",
    "        save_results_to_csv(final_results, best_params, test_accuracy,model_type,threshold_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4a795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
